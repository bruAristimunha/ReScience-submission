{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bruAristimunha/ReScience-submission/blob/Aristimunha-Alves-Pinaya-Camargo/notebook/Jupyter_Paper_Re_Deep_Convolution_Neural_Network_and_Autoencoders_Based_Unsupervised_Feature_Learning_of_EEG_Signals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tvTo4dhiA28C"
   },
   "source": [
    "# 1. [Re] [Deep Convolution Neural Network and Autoencoders-Based Unsupervised Feature Learning of EEG Signals](https://doi.org/10.1109/ACCESS.2018.2833746)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnLTTsbaA28H"
   },
   "source": [
    "## 1.1 Reproduction authors.\n",
    "\n",
    "We have no affiliation with the original authors and our attempts to contact them have failed.\n",
    "\n",
    "[Bruno Aristimunha](https://github.com/bruAristimunha)*<sup>1</sup>, [Diogo Eduardo Lima Alves](https://github.com/DiogoEduardo)*<sup>1</sup>, [Walter Hugo Lopez Pinaya](https://github.com/warvito) <sup>1,2</sup>, [Raphael Y. de Camargo](https://rycamargo.wixsite.com) <sup>1</sup>\n",
    "\n",
    "> <sup>1</sup> Center for Mathematics, Computation and Cognition (CMCC), Federal Univesity of ABC (UFABC), Rua Arcturus, 03. Jardim Antares, São Bernardo do Campo, CEP 09606-070, SP, Brazil.\n",
    "\n",
    "> <sup>2</sup> Department of Psychosis Studies, Institute of Psychiatry, Psychology & Neuroscience, King’s College London, London, UK.\n",
    "\n",
    ">*b.aristimunha@gmail.com, digmogle96@hotmail.com\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2 Original paper authors.\n",
    "\n",
    "Tingxi Wen <sup>2</sup>, Zhongnan Zhang* <sup>2</sup>\n",
    "\n",
    "> <sup>2</sup> Software School, Xiamen University, Xiamen, China.\n",
    "\n",
    "*zhongnan_zhang@xmu.edu.cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LgekfidOA28U"
   },
   "source": [
    "# 2. Abstract (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C63KxYXfA28Z"
   },
   "source": [
    "This paper presents our efforts to reproduce and improve the results achieved by the authors of the original article. We follow the steps and models described in their article and the same public data sets of EEG Signals. Epilepsy affects more than 65 million people globally, and EEG Signals are critical to analyze and recognize epilepsy. Although the efforts in the last years, it is still challenging to extract useful information from these signals and select useful features in a diagnostic application. We construct a deep convolution network and autoencoders-based model (AE-CDNN) in order to perform unsupervised feature learning. We use the AE-CDNN to extract the features of the available data sets, and then we use some common classifiers to classify the features. The results obtained demonstrate that the proposed AE-CDNN outperforms the traditional feature extraction based classification techniques by achieving better accuracy of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_d5lKSqDA28b"
   },
   "source": [
    "Keywords: Replication, Epilepsy, Auto-Enconder, EEG.\n",
    "\n",
    "---\n",
    "\n",
    "Responsible for the reproduction of the results: [Bruno Aristimunha](https://github.com/bruAristimunha) and [Diogo Eduardo Lima Alves](https://github.com/DiogoEduardo).\n",
    "\n",
    "The goals in the work is:\n",
    "  * Make a reproducible report of the results previously reported;\n",
    "\n",
    "  * Improve and deepen the analyzes already carried out in the original article;\n",
    "\n",
    "\n",
    "\n",
    "Advisors: [Walter Hugo Lopez Pinaya](https://github.com/warvito) and [Raphael Y. de Camargo](https://rycamargo.wixsite.com/home) \n",
    "\n",
    "***\n",
    "\n",
    "This work follows the structure below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jzhx0vKYA28d",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-[Re]-Deep-Convolution-Neural-Network-and-Autoencoders-Based-Unsupervised-Feature-Learning-of-EEG-Signals\" data-toc-modified-id=\"1.-[Re]-Deep-Convolution-Neural-Network-and-Autoencoders-Based-Unsupervised-Feature-Learning-of-EEG-Signals-1\">1. [Re] <a href=\"https://doi.org/10.1109/ACCESS.2018.2833746\" target=\"_blank\">Deep Convolution Neural Network and Autoencoders-Based Unsupervised Feature Learning of EEG Signals</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-Reproduction-authors.\" data-toc-modified-id=\"1.1-Reproduction-authors.-1.1\">1.1 Reproduction authors.</a></span></li><li><span><a href=\"#1.2-Original-paper-authors.\" data-toc-modified-id=\"1.2-Original-paper-authors.-1.2\">1.2 Original paper authors.</a></span></li></ul></li><li><span><a href=\"#2.-Abstract-(text)\" data-toc-modified-id=\"2.-Abstract-(text)-2\">2. Abstract (text)</a></span></li><li><span><a href=\"#3.-Imports-Packages-(code)\" data-toc-modified-id=\"3.-Imports-Packages-(code)-3\">3. Imports Packages (code)</a></span></li><li><span><a href=\"#4.-Introduction-(text):\" data-toc-modified-id=\"4.-Introduction-(text):-4\">4. Introduction (text):</a></span></li><li><span><a href=\"#5.-Related-Work-(text)-\" data-toc-modified-id=\"5.-Related-Work-(text)--5\">5. Related Work (text) <a name=\"related\"></a></a></span></li><li><span><a href=\"#6.-Methodology-Proposal-(text-and-code)-\" data-toc-modified-id=\"6.-Methodology-Proposal-(text-and-code)--6\">6. Methodology Proposal (text and code) <a name=\"propose\"></a></a></span><ul class=\"toc-item\"><li><span><a href=\"#6.1-Implementation-Details-(text)\" data-toc-modified-id=\"6.1-Implementation-Details-(text)-6.1\">6.1 Implementation Details (text)</a></span></li><li><span><a href=\"#6.2-Autoencoders\" data-toc-modified-id=\"6.2-Autoencoders-6.2\">6.2 Autoencoders</a></span></li><li><span><a href=\"#6.3-Feature-Learning-Model\" data-toc-modified-id=\"6.3-Feature-Learning-Model-6.3\">6.3 Feature Learning Model</a></span></li><li><span><a href=\"#6.4-Classification\" data-toc-modified-id=\"6.4-Classification-6.4\">6.4 Classification</a></span></li></ul></li><li><span><a href=\"#7.-Experimental-Methodology-\" data-toc-modified-id=\"7.-Experimental-Methodology--7\">7. Experimental Methodology <a name=\"metho\"></a></a></span><ul class=\"toc-item\"><li><span><a href=\"#7.1-Bonn-University-EEG-database\" data-toc-modified-id=\"7.1-Bonn-University-EEG-database-7.1\">7.1 Bonn University EEG database</a></span></li><li><span><a href=\"#7.2-Children's-Hospital-of-Boston-EEG-database\" data-toc-modified-id=\"7.2-Children's-Hospital-of-Boston-EEG-database-7.2\">7.2 Children's Hospital of Boston EEG database</a></span></li><li><span><a href=\"#7.3-Performance-Measures\" data-toc-modified-id=\"7.3-Performance-Measures-7.3\">7.3 Performance Measures</a></span></li><li><span><a href=\"#7.4-Data-Management-(code)\" data-toc-modified-id=\"7.4-Data-Management-(code)-7.4\">7.4 Data Management (code)</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.4.1-Download-Data-(code)\" data-toc-modified-id=\"7.4.1-Download-Data-(code)-7.4.1\">7.4.1 Download Data (code)</a></span></li><li><span><a href=\"#7.4.5-Load,-split-data-and-pre-processing-(code)\" data-toc-modified-id=\"7.4.5-Load,-split-data-and-pre-processing-(code)-7.4.2\">7.4.5 Load, split data and pre-processing (code)</a></span></li></ul></li><li><span><a href=\"#7.5-Performing-feature-learning-(code)\" data-toc-modified-id=\"7.5-Performing-feature-learning-(code)-7.5\">7.5 Performing feature learning (code)</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.5.1-Building-and-saving-dimension-reduction-(code)\" data-toc-modified-id=\"7.5.1-Building-and-saving-dimension-reduction-(code)-7.5.1\">7.5.1 Building and saving dimension reduction (code)</a></span></li></ul></li><li><span><a href=\"#7.6-Classification-process-(code)\" data-toc-modified-id=\"7.6-Classification-process-(code)-7.6\">7.6 Classification process (code)</a></span></li></ul></li><li><span><a href=\"#8.-Results-and-Discussion-\" data-toc-modified-id=\"8.-Results-and-Discussion--8\">8. Results and Discussion <a name=\"resu\"></a></a></span><ul class=\"toc-item\"><li><span><a href=\"#8.1-Checking-the-Variance-(code)\" data-toc-modified-id=\"8.1-Checking-the-Variance-(code)-8.1\">8.1 Checking the Variance (code)</a></span></li><li><span><a href=\"#8.2.-Reproduction-of-the-values-reported-by-the-original-author.\" data-toc-modified-id=\"8.2.-Reproduction-of-the-values-reported-by-the-original-author.-8.2\">8.2. Reproduction of the values reported by the original author.</a></span></li><li><span><a href=\"#8.2.-Extension-of-the-values-reported-by-the-original-author.\" data-toc-modified-id=\"8.2.-Extension-of-the-values-reported-by-the-original-author.-8.3\">8.2. Extension of the values reported by the original author.</a></span><ul class=\"toc-item\"><li><span><a href=\"#8.3.-Precision\" data-toc-modified-id=\"8.3.-Precision-8.3.1\">8.3. Precision</a></span></li><li><span><a href=\"#8.2.2-Specificity-and-Sensitivity\" data-toc-modified-id=\"8.2.2-Specificity-and-Sensitivity-8.3.2\">8.2.2 Specificity and Sensitivity</a></span></li><li><span><a href=\"#8.2.2-F-measure-and-ROC-AUC\" data-toc-modified-id=\"8.2.2-F-measure-and-ROC-AUC-8.3.3\">8.2.2 F-measure and ROC-AUC</a></span></li></ul></li></ul></li><li><span><a href=\"#9.-Conclusion-\" data-toc-modified-id=\"9.-Conclusion--9\">9. Conclusion <a name=\"concl\"></a></a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-10\">References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PdzENqg2A28f"
   },
   "source": [
    "# 3. Imports Packages (code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:46.075265Z",
     "start_time": "2020-04-22T05:29:46.068008Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UsCy1xGIBU-F"
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    base_fold = \"ReScience-submission\"\n",
    "    import os\n",
    "    if os.path.exists(\"./ReScience-submission\"):\n",
    "        pass\n",
    "    else: \n",
    "        !git clone --recurse-submodules -j8 -b Aristimunha-Alves-Pinaya-Camargo --single-branch https://github.com/bruAristimunha/ReScience-submission.git \n",
    "        !pip install -r ReScience-submission/requirements.txt\n",
    "else:\n",
    "    base_fold = \"..\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-UOxTFGA28h"
   },
   "source": [
    "Imports packages which are used by jupyter paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:48.089974Z",
     "start_time": "2020-04-22T05:29:48.084653Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "CIVKT4mSA28i",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"{}/code\".format(base_fold))\n",
    "sys.path.append(\"{}/code/chb-mit/\".format(base_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:30:14.453771Z",
     "start_time": "2020-04-22T05:29:49.975491Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ePGpAYcnA28v",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data_management import (\n",
    "    download_bonn,\n",
    "    download_chbmit,\n",
    "    get_original_results,\n",
    "    load_dataset_boon,\n",
    "    load_dataset_chbmit,\n",
    "    preprocessing_split,\n",
    "    read_history_model,\n",
    ")\n",
    "\n",
    "from variance import (\n",
    "    get_variance_accumulated,\n",
    "    get_variance_by_file,\n",
    "    get_variance_by_person,)\n",
    "\n",
    "from dimension_reduction import (\n",
    "    build_feature,\n",
    "    reduce_dimension,\n",
    ")\n",
    "\n",
    "from classification import (\n",
    "    methods_classification,\n",
    "    run_classification,\n",
    "    save_classification,\n",
    ")\n",
    "\n",
    "from visualization import (\n",
    "    boxplot_difference,\n",
    "    plot_average_metric,\n",
    "    plot_average_metric_baseline,\n",
    "    plot_change_loss,\n",
    "    plot_feature_distribution,\n",
    "    plot_variance_accumulate,\n",
    "    plot_variance_by_file,\n",
    "    plot_variance_by_person,\n",
    "    table_classification_dimension,\n",
    "    table_classification_fold,\n",
    "    table_export_latex,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1GV8wn7Yc0py"
   },
   "source": [
    "Note: The FutureWarning is related to seaborn, this is nothing to worry about\n",
    "[according to this issue](https://github.com/pandas-dev/pandas/issues/31682)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:30:14.459078Z",
     "start_time": "2020-04-22T05:30:14.455334Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fwydnVjmA288",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "EPOCHS = 5000\n",
    "BATCH = 256\n",
    "PATH_BOON = \"{}/data/boon/\".format(base_fold)\n",
    "PATH_CHBMIT = \"{}/data/chbmit/\".format(base_fold)\n",
    "path_original = \"{}/data/original_results/\".format(base_fold)\n",
    "path_figure = \"{}/article/figure\".format(base_fold)\n",
    "path_table = \"{}/article/table\".format(base_fold)\n",
    "\n",
    "chbmit_url = \"https://physionet.org/files/chbmit/1.0.0/\"\n",
    "n_dims = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "\n",
    "\n",
    "name_reducers = [\"mae\", \"maae\", \"mape\", \"pca\", \"srp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:30:14.516268Z",
     "start_time": "2020-04-22T05:30:14.460380Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wzXc7974A29G",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.style.use(\"seaborn-poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.269176Z",
     "start_time": "2020-04-22T05:29:16.036Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3sXP-JVeD7HB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "CONFIG = ConfigProto()\n",
    "CONFIG.gpu_options.allow_growth = True\n",
    "SESSION = InteractiveSession(config=CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDXhsAWrdR7T"
   },
   "source": [
    "Note: Given the implementation of the loss function, it is necessary to define that we will use the GPU via Session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_MY5zuHaxQE"
   },
   "source": [
    "* If you want to get the train results again, please run the following command. Otherwise, just run all the cells.\n",
    "\n",
    "* If you want to recalculate the variance values or reduce the dataset to latent spaces again, please set `run_again_train = True`.\n",
    "\n",
    "* If you want to get the dataset from scratch, set it to `run_again_download = True`. \n",
    "\n",
    "* If you want to get the values from the table and figure again, set `run_again_eval = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.269781Z",
     "start_time": "2020-04-22T05:29:16.049Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_YHNMlt9axQH"
   },
   "outputs": [],
   "source": [
    "run_again_train = False\n",
    "run_again_eval = False\n",
    "run_again_download = False\n",
    "\n",
    "if run_again_train:\n",
    "    # Results of analysis of variance\n",
    "    ! rm -r $\"{}/data/chbmit/variance_accumulated\".format(base_fold)\n",
    "    ! rm -r $\"{}/data/chbmit/variance_file\".format(base_fold)\n",
    "    ! rm -r $\"{}/data/chbmit/variance_person\".format(base_fold)\n",
    "    # Removing the reduced dataset\n",
    "    ! rm -r $\"{}/data/chbmit/reduced\".format(base_fold)\n",
    "    ! rm -r $\"{}/data/boon/reduced\".format(base_fold)\n",
    "    # Removing the history learning and models\n",
    "    ! rm -r $\"{}/data/chbmit/save_model\".format(base_fold)\n",
    "    ! rm -r $\"{}/data/boon/save_model\".format(base_fold)\n",
    "\n",
    "if run_again_download:\n",
    "    ! rm -r $\"{}/data/boon\".format(base_fold)\n",
    "    ! rm -r $\"{}/data/chbmit\".format(base_fold)\n",
    "    \n",
    "! mkdir $path_figure\n",
    "! mkdir $path_table\n",
    "if run_again_eval:\n",
    "    # Figure and Table in article\n",
    "    ! rm -r $path_figure\n",
    "    ! rm -r $path_table\n",
    "    \n",
    "    ! mkdir $path_figure\n",
    "    ! mkdir $path_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38tqbJqyA29O"
   },
   "source": [
    "# 4. Introduction (text):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_lBUuqvA29P"
   },
   "source": [
    "\n",
    "Epilepsy is a chronic neurological disorder, and it is becoming one of the most common neurological diseases in the world <a id=\"ref-1\" href=\"#cite-most_commum:2002\">Reynolds, E. H.</a>. Approximately $1\\%$ of the world's population is affected by epilepsy representing more than 65 million people affected <a id=\"ref-2\" href=\"#cite-global-epilepsy:2019\">Ettore Beghi et. al. 2019</a> <a id=\"ref-3\" href=\"#cite-Epilepsia:2010\">Ngugi, Anthony K. et. al. 2010</a>. This disorder is characterized by the occurrence of spontaneous convulsions due to the abnormal synchronous firing of the cortical neurons <a id=\"ref-4\" href=\"#cite-stafstrom2015seizures\">Stafstrom, Carl E and Carmant, Lionel. 2015</a>. This physical reaction can generate many problems for patients, including physical harm caused by the loss of consciousness, shame and discrimination <a id=\"ref-5\" href=\"#cite-thomas2011confronting\">Thomas, Sanjeev V and Nair, Aparna.</a>.\n",
    "\n",
    "Frequent seizures are dangerous conditions because, at the moment of disruption of the body can occur falls, fractures, burns, car accidents, and other serious physical injuries <a id=\"ref-6\" href=\"#cite-mollaouglu2013injuries\">Mollaoğlu M1, Bolayir E2. 2013</a>. Epilepsy can be defined as a permanent predisposition in the brain to cause epileptic seizures <a id=\"ref-7\" href=\"#cite-stafstrom2015seizures\">Stafstrom, Carl E and Carmant, Lionel. 2015</a>.\n",
    "\n",
    "To be diagnosed with epilepsy, the patient must have at least two seizures that are caused by comorbidities known in the medical literature, such as: extremely low blood sugar <a id=\"ref-8\" href=\"#cite-schauwecker2012effects\">Schauwecker, P. E. 2012. </a>. Even when correctly diagnosed and treated, the epileptic patient still suffers side effects and sporadic seizures. The epileptic seizures can cause even irreversible damage to the brain, and then we can visualize the importance of analyzing epilepsy to improve the life quality and the medical treatments for these patients <a id=\"ref-9\" href=\"#cite-stafstrom2015seizures\">Stafstrom, Carl E and Carmant, Lionel. 2015</a>. \n",
    "\n",
    "To confirm the diagnostic, epileptologists should generally inspect the long-term electroencephalograms (EEG) of the scalp visually. EEG is a measure of the voltage fluctuation generated by the ion current of neurons in the brain, which reflects the activity of the brain’s bio-electricity and may contain many physiological and disease information <a id=\"ref-10\" href=\"#cite-niedermeyer2005electroencephalography\">Niedermeyer, E. and Silva, FH L. 2005 </a>. \n",
    "\n",
    "After the discovery that during a patient's seizure the brain activity changes, the EEG has become the most common epilepsy diagnostic tool. Many studies have been made, and the general problem consists in acquiring methods to classify the patients' EEG signals efficiently <a id=\"ref-11\" href=\"#cite-puce2017review\">Puce, Aina and Hämäläinen, Matti S. 2017</a>. \n",
    "\n",
    "However, this costly task still presents several challenges for automatic crisis detection, among them: The scarce number of public data sets; The lack of standardization in seizure classification methodologies; The lack of standardization of data preprocessing; The cost of a specialist to label time intervals; The unbalance of the time series given the rare occurrence of the event; The difficulty of reproducing the works in the literature <a id=\"ref-12\" href=\"#cite-craik2019deep\">Craik, A.r and He, Y. and Contreras-Vidal, J. L. 2019</a>.\n",
    "\n",
    "With this problem in hand, this paper reproduces the results obtained in <a id=\"ref-1\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>, with public data labeled and preprocessed. In addition, we get new results by combining the proposal classifiers into a classifier by set voting, and we add new metrics.\n",
    "\n",
    "The remainder of this paper is organized as follows: Section [5](#related) presents a few works related to the classification of epileptic seizures in EGG. Section [6](#propose) introduce the methodological proposal employed, and their differences with the work of <a id=\"ref-2\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>. Section [7](#metho) lists the experimental validation process using epilepsy datasets. Section [8](#resu) presents the corresponding results and analyzes our approach. Finally, conclusions were summarized in Section [9](#concl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DN35AKyQA29R"
   },
   "source": [
    "# 5. Related Work (text) <a name=\"related\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMYL0_WeA29T"
   },
   "source": [
    "Several papers use automated methods for detecting seizures. We can extract several discriminative characteristics of the signals, among them, we mention the autocorrelation, probability of synchronization, functional connectivity network properties, EEG morphology and the reconstructed powers of the time series. \n",
    "\n",
    "The oscillatory characteristics present in the time series of patients with epilepsy were extensively studied by temporal frequency analysis for classification (<a id=\"ref-3\" href=\"#cite-saab2005system\">Saab and Gotman 2005</a>, <a id=\"ref-4\" href=\"#cite-kuhlmann2009seizure\">Kuhlmann et al. 2009</a>, <a id=\"ref-5\" href=\"#cite-shoeb2004patient\">Shoeb et al. 2004</a>, <a id=\"ref-6\" href=\"#cite-shoeb2011machine\">Shoeb et al. 2011</a>). Using this technique, we mention the Discrete Wavelet Transform (DWT), which, despite requiring hand-designed parameters, it is the most used (<a id=\"ref-7\" href=\"#cite-ullah2018automated\">Ullah et al. 2018</a>).\n",
    "\n",
    "There is no standard rule for manually label seizures in databases, which makes it difficult to compare the results of these methods. Besides the few papers that use the same sets, few are looking for the same task.\n",
    "\n",
    "In <a id=\"ref-8\" href=\"#cite-chua2011application\">Chua et al. 2011</a>, it is used High Order Spectra (HOS) and spectrum-based energy resources for the automated detection of epilepsy. The proposed method yields good results when using Gaussian Mixture (GMM) for classification ($93.11\\%$ and $88.78\\%$). In <a id=\"ref-9\" href=\"#cite-nicolaou2012detection\">Nicolaou and Georgiou 2012</a>, we have that the authors extracted the entropy of the permutation of the signals, and employed these in an SVM for classification. The result of this methodology, acquired $93.55\\%$ for our first database, in task A vs E.\n",
    "\n",
    "Some researchers have applied Deep Belief Networks (DBNs) to the detection of seizures (<a id=\"ref-10\" href=\"#cite-acharya2018deep\">Acharya et al. 2018</a>). In the line of deep learning algorithms, Convolutional Neural Networks (CNNs) attract growing interest in the literature. In <a id=\"ref-11\" href=\"#cite-hussein2018epileptic\">Hussein et al. 2018</a>, they propose a CNN that learns based on the spectral information of each channel and a LSTM network with a single layer to classify the channels of the objects. \n",
    "\n",
    "<a id=\"ref-12\" href=\"#cite-xun2016detecting\">Xun et al. 2016</a> propose an approach unusual when decoding each window of possible interval as an ``EEG word`` from the `EEG` dictionary. They explore temporal knowledge by learning context information from EEG fragments (Context-EEG). The authors obtained a $22.93\\%$ error rate in the control classification vs epileptic crisis using the second dataset present in <a id=\"ref-13\" href=\"#cite-WenZha\">Wen and Zhang, 2018</a>. \n",
    "\n",
    "<a id=\"ref-14\" href=\"#cite-emami2019autoencoding\">Emami et al. 2019</a> obtained $100\\%$ sensitivity with a simpler methodology than our. For each channel, it builds a autoencoder and through the error of reconstruction is classified. The dataset was self and with no access available. <a id=\"ref-15\" href=\"#cite-ullah2018automated\">Ullah et al. 2018</a> propose a pyramidal model of one dimension for convolution (P-1D-CNN). The method obtains $99.1$ $\\pm$ $0.9$ in our first dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-rCkWOkA29V"
   },
   "source": [
    "# 6. Methodology Proposal (text and code) <a name=\"propose\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MjZ2VDqA29X"
   },
   "source": [
    "In this section, we describe implementation details, as the core is the reproducible aspect of our reference article. We introduce the idea and implementation of autoencoder/feature learning and our version of the model in <a id=\"ref-16\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>, explaining the differences we have made to the original model.\n",
    "\n",
    "In our study, we keep the autoencoder and feature learning as proposed. However, in the classification, in addition to the individual classifiers, we also employ a large ensemble learning classifier, which decides by majority vote the object class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSlOnhflA29Y"
   },
   "source": [
    "## 6.1 Implementation Details (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vr5gFS2hA29Z"
   },
   "source": [
    "We decided to reproduce the implementation described in the article using Keras (<a id=\"ref-17\" href=\"#cite-chollet2018keras\">Chollet et al. 2018</a>) and backend in TensorFlow (<a id=\"ref-18\" href=\"#cite-tensorflow\">Abadi et al. 2016</a>). Our repository includes a list of all the required libraries employed in acquiring the datasets and running the model (the original and the proposed one). According to the methodology proposed in <a id=\"ref-19\" href=\"#cite-Fuente:2019\">la Fuente and Aduviri 2019</a>, we store all the checkpoints for the trained models, for reproduction purposes. Besides that, the training logs can be visualized using TensorBoard tool.\n",
    "\n",
    "Given the lack of information about implementation in the original paper, some assumptions or cuts are made: \n",
    "\n",
    "* The number of epoch in the AutoEnconder is assumed to be $5000$; \n",
    "* The number of samples per batch size is assumed to be $256$; \n",
    "* A column of the first database is removed, there is disagreement in the literature on the total instances, $4097$ or $4096$. In the specific database we use there is $4097$. The removed attribute is at the endpoint of each object; \n",
    "* In the second dataset, we use the channel reported by the author to train the AutoEncoder;\n",
    "* The loss function presented in equation $12$ of the <a id=\"ref-16\" href=\"#cite-WenZha\">Wen and Zhang 2018</a> was implemented and we also compared the result obtained with __MAPE__; \n",
    "* The value of the seeds selected in all classifiers, data splitting and elsewhere was $42$; \n",
    "* The train-validation ratio was $80\\%-20\\%$ to AutoEnconder, in classifiers we use cross-validation with 5 or 10-fold; \n",
    "* Given a sizing problem, we resized the values using the MinMax method, before the classification process.\n",
    "* The classifier presented in the final subsection (NN2) was not reproduced for lack of information; \n",
    "\n",
    "The experiments were performed using a CPU with Intel Core i7-5930K with 3.50 GHz and two GPUs: Nvidia Quadro K5200 and GeForce GTX 970. Some experiments were also run using Nvidia Titan X.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vD4iAGsDA29a"
   },
   "source": [
    "## 6.2 Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "guDH6GwnA29e"
   },
   "source": [
    "The autoencoder implemented is a specific case of neural network structure. It is formed by three layers, an input layer, an output layer and a hidden layer. The training is done to set the weights of the hidden layer to force the input layer and output layer to be as close to each other as possible. Our features are extracted from the hidden layer, which reduces the dimension of data. \n",
    "\n",
    "Therefore we have a encoding process and a decoding process, and we obtain the hidden layer $h$ by applying the encoding function:\n",
    "\n",
    "\\begin{equation}\n",
    "h = encoder(x) = g(W*x+b),\n",
    "\\end{equation}\n",
    "\n",
    "where $W$ is the weight matrix between the input layer and hidden layer. In the decoding function the hidden layer $h$ is the input and $y = decoder(h)$ as output, the function is defined as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "y = decoder(x) = g(W'*x + b'),\n",
    "\\end{equation}\n",
    "\n",
    "where $W'$ is the weight matrix between the hidden layer and output layer. Since we want the input and output to be as close as possible, we have the object function for the model training process:\n",
    "\n",
    "\\begin{equation}\n",
    "\\min \\sum |y^{(i)} - x^{(i)}|,\n",
    "\\end{equation}\n",
    "\n",
    "where $y^{(i)}$ is the output signal and $x^{(i)}$ is the input signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "299qqvZDA29g"
   },
   "source": [
    "## 6.3 Feature Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XikzH8wOA29i"
   },
   "source": [
    "In this subsection, we will omit equations and minor details (for complete information, see <a id=\"ref-21\" href=\"#cite-Shoeb\">Shoeb and Guttag 2010</a>, <a id=\"ref-22\" href=\"#cite-emami2019autoencoding\">Emami et al. 2019</a>). Since we have the dimension reduced by autoencoder we focus on the next challenge: how to obtain effective features from EEG signals. The AE-CDNN implemented follows the steps:\n",
    "\n",
    "    Encoder: sample input, convolution layer, down-sampling layer, reshape operation, full connection layer, and the feature coding.\n",
    "    Decoder: feature coding as input, full connection layer, reshape operation, deconvolution layer, up-sampling layer and the reconstruction samples.\n",
    "\n",
    "Basically, the convolution layer acts as our feature extractor. It performs many successive convolution calculations of the input data and the expectation is to maintain the main components of the input data. The pooling layer is a down-sampling method which reduces data dimension. It uses windows to slide and extract the feature maps. These intervals do not overlap each other, and with then we obtain the pooled feature maps. The feature sizes tested were $m \\in \\{2, 4, 8, 16, 32, 64, 128, 256\\}$[<sup>1</sup>](#fn1 \"footnote 1\").\n",
    "\n",
    "\n",
    "The convolution and pooling operations can be iterated multiple times. Reshape operation uses the pooled feature maps to construct an one-dimension vector and a full-connection layer to transform this one-dimension vector. \n",
    "\n",
    "Considering $x$ as the input and $y$ as the output, now we need to re-transform the one-dimension vector which will generate the $y$ output, recall we want to minimize the difference between $x$ and $y$ and we have the following equation to calculate loss Mean Absolute Error:\n",
    "\n",
    "$$\\text{Loss MAE}= \\frac{1}{N} \\sum_{i=1}^N |x^{(i)} - y^{(i)}| .$$\n",
    "\n",
    "\n",
    "In addition, given the possible interpretations in the original text, we have also used/implemented two loss functions, namely Mean Absolute Percentage Error - MAPE and Mean Absolute Average Error - MAAE [<sup>2</sup>](#fn2 \"footnote 2\"), that are contained below:\n",
    "\n",
    "\n",
    "$$\\text{Loss MAPE}= \\frac{1}{N} \\sum_{i=1}^N \\frac{|x^{(i)} - y^{(i)}|}{x^{(i)}} .$$\n",
    "\n",
    "The difference between the loss functions is only in the fact that one takes in the denominator the value per $x^{(i)}$ and the other takes the average ${\\bar x^{(i)}}$.\n",
    "\n",
    "$$\\text{Loss MAAE}= \\frac{1}{N} \\sum_{i=1}^N \\frac{|x^{(i)} - y^{(i)}|}{{\\bar x^{(i)}}} .$$\n",
    "\n",
    "---\n",
    "\n",
    "<sup>1. <span id=\"fn1\"> Size $m = 256$ has not been tested in <a id=\"ref-23\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>.</span></sup>\n",
    "\n",
    "<sup>2. <span id=\"fn2\"> The formula presented in the original article by <a id=\"ref-23\" href=\"#cite-WenZha\">Wen and Zhang 2018</a> differs from the MAPE formula, despite having similar intuitions. Thus, we chose to implement this loss equation, and we have not found its use elsewhere.</span></sup> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRwqN-jXA29j"
   },
   "source": [
    "## 6.4 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GeLGR6oTA29m"
   },
   "source": [
    "Since we have extracted the features with reduced dimension, we use supervised learning models on these features in order to classify the EEG signals. We evaluate each classifier and then we compare the results obtained with each one. The classical classifiers used are: K-Nearest Neighbors (K-NN), Support-Vector Machine - Linear Kernel and Radial Basis Kernel (SVM1, SVM2), Decision Tree (DT), Random Forest (RT), Multilayer Neural Network (MLP), Adaptive Boosting Algorithm (ADB) and Gaussian Naive Bayesian (GNB).\n",
    " \n",
    "The proposed modification combines these classifiers and creates a single classifier that decides by voting. In short, the classifiers were combined by ensemble learning, and the result of the classification became the classification most voted by the classifiers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2LhxY13A29n"
   },
   "source": [
    "---\n",
    "\n",
    "# 7. Experimental Methodology <a name=\"metho\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3-PvgiErA29p"
   },
   "source": [
    "In this paper, as in our reference paper <a id=\"ref-24\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>, we use unsupervised learning method in EEG signals in order to obtain useful features. This process is needed because the original data is high-dimensional. By using the auto-encoder, we can extract features with reduced dimension.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O48uPAxSA29r"
   },
   "source": [
    "---\n",
    "## 7.1 Bonn University EEG database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhMmaflCA29r"
   },
   "source": [
    "We can use different approaches to detect epileptic crisis. Then, to acquire a comparative measure, we verify our outputs using the method described in [6](#propose) and the original one showed in <a id=\"ref-25\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>. This database is public and was published by <a id=\"ref-26\" href=\"#cite-Andrzejak\">G. Andrzejak et al. 2002</a>. The study groups were the control, inter-ictal and ictal distributed into five sets (denotated A-E). Each containing $100$ records of $23.6$ seconds duration and frequency of $173.6$ Hz on a single channel, with $12$-bit resolution. Each data segment has 4097 samples. These recordings underwent a pre-processing in which the signals had a band filter between $0.53$ to $40$ Hz. There was also the removal of artifacts such as muscle movements or flicker movements.\n",
    "\n",
    "Using labels A, B, C, D and E for the subsets, we have that A and B contain records of 5 healthy volunteers. Set A corresponds to open-eye activity and subset B to closed-eye activity. The subsets C and D have signals during the absence (interictal epileptiform activity) of 5 epileptic patients. And E records the signals during epileptic patients' seizure (ictal intervals). According to <a id=\"ref-27\" href=\"#cite-kamath2015analysis\">Kamath 2015</a>, this dataset is a compilation of recordings under different conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0RFNpnFIA29s"
   },
   "source": [
    "## 7.2 Children's Hospital of Boston EEG database\n",
    "\n",
    "The second database, also public, contains the EEG signals from a Children\\`s Hospital of Boston\n",
    "<a id=\"ref-5\" href=\"#cite-shoeb2004patient\">Shoeb et al. 2004</a>. It was recorded by measuring the brain's electrical activity to obtain EEG signals by connecting multiple electrodes to the patients’ scalp. The data incorporates the EEG signals of 23 children with refractory epilepsy.\n",
    "\n",
    "This database, built in partnership with the Massachusetts Institute of Technology (MIT), has $5$ men and $18$ women between $3$ and $22$ years. The frequency range was $256$ Hz with $16$ resolution bits. Most patients contain $ 23 $ channels and some with $24$ channels. In contrast to the first set of data, we have multiple channels here, then we need to select channels. The selection followed the methodology used in \\cite{shoeb2009application}, which analyzes the variance of each patient, and after that, chooses the channel of greater variance to represent that individual. The channel reported by the authors was `FT9-FT10`.\n",
    "\n",
    "In the data of the first ten patients, 200 windows of the same size of the control set were chosen from the epileptic patients we choose $200$, with size of $4096$, in the same way of the control group.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uw-ParALA29t"
   },
   "source": [
    "## 7.3 Performance Measures\n",
    "\n",
    "According to  <a id=\"ref-28\" href=\"#cite-roy2019deep\">Roy et al. 2019</a>, most of the state-of-the-art systems for epilepsy use the metrics defined below. The adaptation of these metrics for evaluating our system contributes to fair comparison with state-of-the-art systems. The definitions of these metrics are given in Table [1](#table1).\n",
    "\n",
    "\n",
    "\n",
    "| **Acurracy**      | **Precision** | **Specificity** | **Sensitivity/Recall** | **F-Measure**                                                |\n",
    "|:--------------------------:|:----------------------:|:------------------------:|:------------------------:|:---------------------------------------------------------------------:|\n",
    "| $\\frac{TP+TN}{(TP+TN+FP+FN)}$ | $\\frac{TP}{TP+FP}$      | $\\frac{TN}{TN+FP}$        | $\\frac{TP}{FN+TP}$        | $\\frac{2 * Pre * Sens}{Sens+Pre}$ |\n",
    "\n",
    "> Table 1. Metrics and Definition use in our paper. Only the Acurracy was considered in <a id=\"ref-29\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>. <a name=\"table1\"></a>\n",
    "\n",
    "where False Negatives - FN is the number of epileptic cases, which are predicted as control, True Positives - TP is the number of epileptic cases, which are predicted as epileptic, True Negative - TN is the number of control case that is predicted as control and False Positives - FP is the number of control cases that are identified as epileptic by the system. \n",
    "\n",
    "In addition, there was also the AUC-ROC (Area Under The Curve - Receiver Operating Characteristic) defined as the cumulative distribution function of the true positive rate vs the false-negative rate denoted by a threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OSGfVqUhA29v"
   },
   "source": [
    "---\n",
    "## 7.4 Data Management (code)\n",
    "\n",
    "In this section, we describe the operation required to reproduce the results. So, here is the code for downloading, loading, sampling, and splitting the dataset.\n",
    "\n",
    "### 7.4.1 Download Data (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZtIEDb5A29x"
   },
   "source": [
    "The EEG data obtained from the experiment reported above  are required for reproduction. These files have $11$ Mb in Bonn University and $25$ Gb in Children's Hospital of Boston database. You do need them for all the analysis in the Jupyter Paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmNvkggJA29y"
   },
   "source": [
    "*Bonn University database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.270337Z",
     "start_time": "2020-04-22T05:29:16.098Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "nCmS5JKtA290"
   },
   "outputs": [],
   "source": [
    "boon_path_child_fold = download_bonn(PATH_BOON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nG1feUbhA2-C"
   },
   "source": [
    "*Children's Hospital of Boston EEG database*\n",
    "\n",
    "By default, this github contains the second dataset. If you want to reproduce the sampling process, please delete the `as_dataset` folder in the chbmit folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.270972Z",
     "start_time": "2020-04-22T05:29:16.108Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "XdROpwhIA2-E",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chbmit_path_child_fold = download_chbmit(url_base=chbmit_url,\n",
    "                                         path_save=PATH_CHBMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T16:22:44.025132Z",
     "start_time": "2020-03-11T16:22:44.019409Z"
    },
    "colab_type": "text",
    "id": "suG9n94dA2_E"
   },
   "source": [
    "### 7.4.5 Load, split data and pre-processing (code)\n",
    "\n",
    "*Bonn University EEG database*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.271578Z",
     "start_time": "2020-04-22T05:29:16.119Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0rCzPgb5A2_F",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_boon, y_boon = load_dataset_boon(PATH_BOON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.272221Z",
     "start_time": "2020-04-22T05:29:16.126Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gHIgxnnrA2_M",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_boon, X_test_boon, Y_train_boon, Y_test_boon = preprocessing_split(X_boon, y_boon,\n",
    "                                                                           test_size=TEST_SIZE,\n",
    "                                                                           random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jcP2dCtjA2_S"
   },
   "source": [
    "*Children's Hospital of Boston EEG database*\n",
    "\n",
    "By default, this github contains the second dataset. If you want to reproduce the sampling process, please delete the `as_dataset` folder in the chbmit folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.272849Z",
     "start_time": "2020-04-22T05:29:16.135Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "XqL1KvBKA2_U",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_chbmit, y_chbmit = load_dataset_chbmit(PATH_CHBMIT,  pre_load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.273357Z",
     "start_time": "2020-04-22T05:29:16.143Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "FIvI-3wZA2_d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_chbmit, X_test_chbmit, Y_train_chbmit, Y_test_chbmit = preprocessing_split(X_chbmit, y_chbmit,\n",
    "                                                                                   test_size=TEST_SIZE,\n",
    "                                                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pVZudvqqA2_k"
   },
   "source": [
    "## 7.5 Performing feature learning (code)\n",
    "\n",
    "In this section we present the dimension reduction process.\n",
    "\n",
    "### 7.5.1 Building and saving dimension reduction (code)\n",
    "\n",
    "In this sub-section has the dimension reduction process, in each dataset, either through methods baseline with Principal Component Analysis (`PCA`), Sparse Random Projection (`SRP`), or the proposal with Auto Encoder (`AE`).\n",
    "\n",
    "*Bonn University EEG database*\n",
    "\n",
    "__Auto Encoder (`AE`)__\n",
    "\n",
    "* Mean absolute error (`MAE`)\n",
    "* Mean absolute average error (`MAAE`)\n",
    "* Mean absolute percentage error (`MAPE`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.273945Z",
     "start_time": "2020-04-22T05:29:16.151Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6Ri1pCKiA2_w"
   },
   "outputs": [],
   "source": [
    "if run_again_train:\n",
    "    methods_ae_maae_boon = [[\n",
    "        build_feature(X_train_boon, X_test_boon,\n",
    "                      Y_train_boon, Y_test_boon,\n",
    "                      PATH_BOON, EPOCHS, BATCH, type_loss, dim)\n",
    "        for dim in n_dims]\n",
    "        for type_loss in [\"mae\", \"maae\", \"mape\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xzsUOHFwA2_1"
   },
   "source": [
    "__Principal Component Analysis (`PCA`)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.274388Z",
     "start_time": "2020-04-22T05:29:16.159Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8-goo9dEA2_2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "methods_pca_boon = [\n",
    "    reduce_dimension(X_boon, y_boon,\n",
    "                     PATH_BOON, \"pca\", dim)\n",
    "    for dim in n_dims]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ds6KTts6A2_-"
   },
   "source": [
    "__Sparse Random Projection (`SRP`)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.274867Z",
     "start_time": "2020-04-22T05:29:16.170Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "lZpo7bVhA2__",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "methods_srp_boon = [\n",
    "    reduce_dimension(X_boon, y_boon,\n",
    "                     PATH_BOON, \"srp\", dim)\n",
    "    for dim in n_dims]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SH-IxCgwA3AD"
   },
   "source": [
    "*Children's Hospital of Boston EEG database*\n",
    "\n",
    "__Auto Encoder (`AE`)__\n",
    "\n",
    "* Mean absolute error (`MAE`)\n",
    "* Mean absolute average error (`MAAE`)\n",
    "* Mean absolute percentage error (`MAPE`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.275325Z",
     "start_time": "2020-04-22T05:29:16.179Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "a578QL3TA3AE"
   },
   "outputs": [],
   "source": [
    "if run_again_train:\n",
    "    methods_ae_mae_chbmit = [[\n",
    "        build_feature(X_train_chbmit, X_test_chbmit,\n",
    "                      Y_train_chbmit, Y_test_chbmit,\n",
    "                      PATH_CHBMIT, EPOCHS, BATCH, type_loss, dim)\n",
    "        for dim in n_dims]\n",
    "        for type_loss in [\"mae\", \"maae\", \"mape\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mCjdBKzMA3AI"
   },
   "source": [
    "__Principal Component Analysis (`PCA`)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.275769Z",
     "start_time": "2020-04-22T05:29:16.187Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "glmhIRCwA3AI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "methods_pca_chbmit = [reduce_dimension(X_chbmit, y_chbmit,\n",
    "                                       PATH_CHBMIT, \"pca\", dim)\n",
    "                      for dim in n_dims]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tTklRS3_A3AO"
   },
   "source": [
    "__Sparse Random Projection (`SRP`)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.276203Z",
     "start_time": "2020-04-22T05:29:16.195Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fPB0ip55A3AO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "methods_srp_chbmit = [\n",
    "    reduce_dimension(X_chbmit, y_chbmit,\n",
    "                     PATH_CHBMIT, \"srp\", dim)\n",
    "    for dim in n_dims]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6r3wuB0A3AS"
   },
   "source": [
    "---\n",
    "## 7.6 Classification process (code)  \n",
    "\n",
    "*Bonn University EEG database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:32:23.095817Z",
     "start_time": "2020-04-22T05:30:17.067077Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "W6oD0h3pA3AU"
   },
   "outputs": [],
   "source": [
    "metrics_boon = [run_classification(path_dataset=PATH_BOON,\n",
    "                                   name_type=name_type,\n",
    "                                   range_values=n_dims)\n",
    "                for name_type in name_reducers]\n",
    "\n",
    "metrics_boon = dict(zip(name_reducers, metrics_boon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:44:21.838726Z",
     "start_time": "2020-03-11T15:44:21.826763Z"
    },
    "colab_type": "text",
    "id": "4DUhXVTRA3Ad"
   },
   "source": [
    "*Children's Hospital of Boston EEG database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:34:17.820872Z",
     "start_time": "2020-04-22T05:32:23.096936Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "PcWcZQbwA3Af"
   },
   "outputs": [],
   "source": [
    "metrics_chbmit = [run_classification(path_dataset=PATH_CHBMIT,\n",
    "                                     name_type=name_type,\n",
    "                                     range_values=n_dims)\n",
    "                  for name_type in name_reducers]\n",
    "\n",
    "metrics_chbmit = dict(zip(name_reducers, metrics_chbmit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qVmhtbMCA3Aj"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EDVJe-cZA3Aj"
   },
   "source": [
    "# 8. Results and Discussion <a name=\"resu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lq6cvZOiA2-M"
   },
   "source": [
    "In this section, we analyze three analytical approaches. In the first subsection we analyze the variance present in the channels. The second contains the reproduction of all possible tables and figures, with a discussion of the reasons for the differences. In the third we present an extension of the results, evaluating other classification metrics, proposing a new classifier and varying the classifier parameters.\n",
    "\n",
    "-----------------------------\n",
    "\n",
    "## 8.1 Checking the Variance (code) \n",
    "\n",
    "According to the original authors, the choice of the channel in the second dataset observed the variance present in the channels. For that, they followed the methodology:\n",
    "\n",
    ">1) calculate the variance of each channel in each sample, and select the channel with the maximum variance for each sample; 2) count these channels.\n",
    "\n",
    "Thereby, we model the three interpretations of what is the sample defined by the author. In the first, we analyzed each recording file of the dataset as a sample, having an average length of $921600$ referring to the recorded $3600s$. In these files, we compute and list the electrode with more variance and discard the rest. We accumulate and count for all files. The results obtained can be seen in the Figure below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.277493Z",
     "start_time": "2020-04-22T05:29:16.222Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jZQMN5fEaxSn"
   },
   "outputs": [],
   "source": [
    "variance_by_file = get_variance_by_file(PATH_CHBMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.277974Z",
     "start_time": "2020-04-22T05:29:16.228Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "m4IlRuEraxSs"
   },
   "outputs": [],
   "source": [
    "fig_by_file = plot_variance_by_file(variance_by_file)\n",
    "\n",
    "plt.savefig(\"{}/variance_per_file.pdf\".format(path_figure), \n",
    "            bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yywqSpRA2-e"
   },
   "source": [
    "The results obtained in the first scenario were not consistent with those reported by the author.\n",
    "\n",
    "In the second interpretation, we understand that each sample is accumulated per person with all his recordings. So the variance was calculated in parallel in the files and combined for each person. For each person, we count the occurrence of the channel with more variance. As shown in Figure below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.278429Z",
     "start_time": "2020-04-22T05:29:16.236Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "p8bYOT_MA2-i",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variance_per_person = get_variance_by_person(PATH_CHBMIT, \n",
    "                                             range_= (1,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.278872Z",
     "start_time": "2020-04-22T05:29:16.244Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WN5upnkkA2-r"
   },
   "outputs": [],
   "source": [
    "fig_by_person = plot_variance_by_person(variance_per_person)\n",
    "plt.savefig(\"{}/variance_per_person.pdf\".format(path_figure),\n",
    "            bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxUPvfUdA2-x"
   },
   "source": [
    "The results obtained in the second scenario were not consistent with those reported by the author.\n",
    "\n",
    "Finally, as a final interpretation, we calculate the cumulative variance across all people and all records, thus, we did not perform a sampling process. In other words, we put all the files together and calculate the variance as if it were a single record. For this, we compute the variance, number of points and average per channel in each file and accumulate through the cumulative variance calculation algorithm. The result of this analysis approach can be seen in Figure below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.279306Z",
     "start_time": "2020-04-22T05:29:16.251Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7YxtPlAqA2-z",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accumulate_var = get_variance_accumulated(PATH_CHBMIT, range_= (1,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.279928Z",
     "start_time": "2020-04-22T05:29:16.258Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UNpNP2tNA2-8"
   },
   "outputs": [],
   "source": [
    "fig_accumulate = plot_variance_accumulate(accumulate_var)\n",
    "plt.savefig(\"{}/variance_all.pdf\".format(path_figure), \n",
    "            bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IqLlFmPQA2_E"
   },
   "source": [
    "The results obtained in the first, second and third interpretations were not consistent with those reported by the author. There is still another possible scenario, however, not reproducible, where the authors randomly sampled the dataset and evaluated the variance.\n",
    "\n",
    "However, given the associated uncertainty, we decided to repeat the choice of the channel `FT9-FT10`, although this is not the one with the most variance in the modeled scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "There is still another possible scenario, however, not reproducible, being the possibility that the authors randomly sampled the dataset and in this they verified the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y2UZF7EkA3Ak"
   },
   "source": [
    "## 8.2. Reproduction of the values reported by the original author.\n",
    "\n",
    "The results obtained in our reproduction experiment, for the first dataset, are presented in Accuracy Tables [2](#table:accuracy-ae-l1-d1), [3](#table:accuracy-ae-l2-d1) and the differences between results can be seen in Figures below. We employed the same methodology as the one used in the original paper, performing a $5$-fold cross-validation for each classifier, and we show the mean values. For each table reproduced, we also present the original result and the difference between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.280458Z",
     "start_time": "2020-04-22T05:29:16.270Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GS67n9wFA3Ak",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reprod_table_2, reprod_2_style = table_export_latex(path_save=path_table,\n",
    "                                                    dataset=metrics_boon,\n",
    "                                                    name_type=\"mae\",\n",
    "                                                    metric=\"accuracy\",\n",
    "                                                    name_dataset=\"boon\",\n",
    "                                                    original=True,\n",
    "                                                    proposed=True)\n",
    "reprod_2_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.280937Z",
     "start_time": "2020-04-22T05:29:16.276Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ye18zb3yA3Ao",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "origin_table_2 = get_original_results(2, path_original)\n",
    "origin_table_2.style.set_caption(\n",
    "    \"Original accuracy values, analysis of Table 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.281426Z",
     "start_time": "2020-04-22T05:29:16.282Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OP_vWKmeA3Ar"
   },
   "outputs": [],
   "source": [
    "fig_diff_2 = boxplot_difference(reprod_table_2, origin_table_2)\n",
    "\n",
    "plt.savefig(\"{}/table_2.pdf\".format(path_figure),\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DY3Y0hjrA3A0"
   },
   "source": [
    "> Table 2 and Figure 2: Classification Accuracy Results of AE-CDNN-MAE for Dataset 1<a name=\"table:accuracy-ae-l1-d1\"></a>, Reproduced and Difference.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.281962Z",
     "start_time": "2020-04-22T05:29:16.289Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-FPs0pEyA3A0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reprod_table_3, reprod_3_style = table_export_latex(path_save=path_table,\n",
    "                                                    dataset=metrics_boon, \n",
    "                                                    name_type=\"maae\",\n",
    "                                                    metric=\"accuracy\", \n",
    "                                                    name_dataset=\"boon\",\n",
    "                                                    original=True, \n",
    "                                                    proposed=True)\n",
    "reprod_3_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.282438Z",
     "start_time": "2020-04-22T05:29:16.297Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "N6BOu3BFA3A-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "origin_table_3 = get_original_results(3, path_original)\n",
    "origin_table_3.style.set_caption(\n",
    "    \"Original accuracy values, analysis of Table 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.282890Z",
     "start_time": "2020-04-22T05:29:16.303Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gNdTH0T2A3BD"
   },
   "outputs": [],
   "source": [
    "fig_diff_3 = boxplot_difference(reprod_table_3, origin_table_3)\n",
    "\n",
    "plt.savefig(\"{}/table_3.pdf\".format(path_figure), \n",
    "            bbox_inches=\"tight\", \n",
    "            dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T00:12:10.326977Z",
     "start_time": "2020-03-22T00:12:10.321350Z"
    },
    "colab_type": "text",
    "id": "M08abvcdA3BH"
   },
   "source": [
    "> Table 3 and Figure 3: Classification Accuracy Results of AE-CDNN-L2 for Dataset 1<a name=\"table:accuracy-ae-l2-d1\"></a>.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.283380Z",
     "start_time": "2020-04-22T05:29:16.312Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2zP0n2fHA3BH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reprod_table_4, reprod_4_style = table_export_latex(path_save=path_table,\n",
    "                                                    dataset=metrics_chbmit, \n",
    "                                                    name_type=\"mae\",\n",
    "                                                    metric=\"accuracy\", \n",
    "                                                    name_dataset=\"chbmit\",\n",
    "                                                    original=True, \n",
    "                                                    proposed=True)\n",
    "reprod_4_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.283843Z",
     "start_time": "2020-04-22T05:29:16.319Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "H6fuvAOfA3BO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "origin_table_4 = get_original_results(4, path_original)\n",
    "origin_table_4.style.set_caption(\n",
    "    \"Original accuracy values, analysis of Table 4.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.284367Z",
     "start_time": "2020-04-22T05:29:16.325Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8cfsiyM8A3BR"
   },
   "outputs": [],
   "source": [
    "fig_diff_4 = boxplot_difference(reprod_table_4, origin_table_4)\n",
    "\n",
    "plt.savefig(\"{}/table_4.pdf\".format(path_figure), \n",
    "            bbox_inches=\"tight\", \n",
    "            dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T00:12:34.628700Z",
     "start_time": "2020-03-22T00:12:34.622998Z"
    },
    "colab_type": "text",
    "id": "gEtZ2TLpA3BW"
   },
   "source": [
    "> Table 4 and Figure 4: Classification Accuracy Results of AE-CDNN-MAE for Dataset 2<a name=\"table:accuracy-ae-l1-d2\"></a>.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.284835Z",
     "start_time": "2020-04-22T05:29:16.335Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tDGFjgJSA3BW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reprod_table_5, reprod_5_style = table_export_latex(path_save=path_table,\n",
    "                                                    dataset=metrics_chbmit, \n",
    "                                                    name_type=\"maae\",\n",
    "                                                    metric=\"accuracy\", \n",
    "                                                    name_dataset=\"chbmit\",\n",
    "                                                    original=True, \n",
    "                                                    proposed=True)\n",
    "reprod_5_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.285305Z",
     "start_time": "2020-04-22T05:29:16.341Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "f8jiewvWA3Bc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "origin_table_5 = get_original_results(5, path_original)\n",
    "origin_table_5.style.set_caption(\n",
    "    \"Original accuracy values, analysis of Table 5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.285801Z",
     "start_time": "2020-04-22T05:29:16.346Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Z77pi1vcA3Bi"
   },
   "outputs": [],
   "source": [
    "fig_box_5 = boxplot_difference(reprod_table_5, origin_table_5)\n",
    "\n",
    "plt.savefig(\"{}/table_5.pdf\".format(path_figure), \n",
    "            bbox_inches=\"tight\", \n",
    "            dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "egmjJb_0A3Bn"
   },
   "source": [
    "> Table 5 and Figure 5: Classification Accuracy Results of AE-CDNN-L2 for Dataset 2<a name=\"table:accuracy-ae-l2-d2\"></a>.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvUnrdD1A3Bn"
   },
   "source": [
    "We can perceive some differences when compared to the original results. In Table [3](#table:accuracy-ae-l2-d1), we acquired the best average with a dimension equal to 64, while the original document acquired the best average when the dimension is equal to 128. The original document acquired higher accuracy values in most cases, even though when the dimension is equal to 2 or 4, our accuracy values are higher. The best precision in our article and in the original article was obtained by the random forest algorithm.\n",
    "\n",
    "\n",
    "Considering Dataset 2 and Tables we acquired similar results when compared with the results obtained by the original authors. In general, the original paper acquired a maximum accuracy greater than those obtained by our reproduction implementation, but the average and unique values per dimension are close in most cases considering both functions AE-CDNN-MAE and AE-CDNN-MAAE. However, for Dataset 1 the accuracy values obtained in this paper are significantly lower than the ones obtained by the original paper considering both AE-CDNN-MAE and AE-CDNN-MAAE, as shown in Figure: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.286353Z",
     "start_time": "2020-04-22T05:29:16.356Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "srSaoInoA3Bo"
   },
   "outputs": [],
   "source": [
    "fig_avg_acc = plot_average_metric(metrics_boon[\"mae\"], \n",
    "                                  metrics_boon[\"maae\"],\n",
    "                                  metrics_chbmit[\"mae\"], \n",
    "                                  metrics_chbmit[\"maae\"],\n",
    "                                  names=[\"AE-CDNN-MAE\", \"AE-CDNN-MAAE\"])\n",
    "\n",
    "plt.savefig(\"{}/average-MAE-MAAE.pdf\".format(path_figure), \n",
    "            bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yrreGdaA3Bv"
   },
   "source": [
    "> Figure 6: Average Accuracy Results of AE-CDNN-MAE and AE-CDNN-MAAE, with different dimension values in the two dataset <a name=\"fig:average-cdnn\"></a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9rlRxNW0A3Bw"
   },
   "source": [
    "When analyzing the behavior of the different loss functions, we see that the MAAE function does not always obtain superior results than the MAE function. The same is observed in the original article, as well as a similar behavior, but the average accuracy obtained are significantly higher than those obtained by our reproduction. Similarly, when we analyze the loss function MAAE and MAPE, in Figure below, we have that the behavior of both is not very divergent, being MAAE generating a higher accuracy in the first dataset. In the second dataset, MAPE has a more stable behavior and generates greater accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.286798Z",
     "start_time": "2020-04-22T05:29:16.365Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "RMERotKmA3Bx"
   },
   "outputs": [],
   "source": [
    "fig_avg_acc = plot_average_metric(metrics_boon[\"maae\"], \n",
    "                                  metrics_boon[\"mape\"],\n",
    "                                  metrics_chbmit[\"maae\"], \n",
    "                                  metrics_chbmit[\"mape\"],\n",
    "                                  [\"AE-CDNN-MAAE\", \"AE-CDNN-MAPE\"])\n",
    "\n",
    "plt.savefig(\"{}/average-MAAE-MAPE.pdf\".format(path_figure), \n",
    "            bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uCwgAdmzA3CB"
   },
   "source": [
    "> Figure 6: Average Accuracy Results of AE-CDNN-MAAE and AE-CDNN-MAPE in the two dataset <a name=\"fig:average-cdnn-mape\"></a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_zXKjWbNA3CD"
   },
   "source": [
    "When observing the values obtained in the classification, in the k-fold, we have that the accuracy values follow the proportion of the data, indicating the non-learning of the classification methods. We observed below the result for the accuracy inspection, for the cross validation, for $m = 2$. Analyzing the accuracy obtained by classifiers in Tables 3 and 4 we observe the values obtained by AE-CDNN-MAAE and AE-CDNN-MAE are close, however the function AE-CDNN-MAAE acquired smoothly better results and with less variation, in general. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.287251Z",
     "start_time": "2020-04-22T05:29:16.373Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kHbVOjf1A3CD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boon_mae_2 = table_classification_fold(metrics_boon[\"mae\"], dimension=2)\n",
    "\n",
    "boon_mae_2.to_latex(\"{}/acc-mae-boon-fold-2.tex\".format(path_table),\n",
    "                    caption=\"Accuracy in Classification, with loss MAE\"\\\n",
    "                    \", on each fold cross-validation, for Dataset 1.\",\n",
    "                    label=\"table:acc-mae-boon-fold-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T04:05:29.463242Z",
     "start_time": "2020-03-30T04:05:29.457338Z"
    },
    "colab_type": "text",
    "id": "KjE9IDafA3CH"
   },
   "source": [
    "> Table 6: Accuracy in Classification, with loss `MAE`, on each fold cross-validation, for Dataset 1<a name=\"table:accuracy-ae-l1-d1-fold\"></a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.287708Z",
     "start_time": "2020-04-22T05:29:16.382Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JzfkDjY_A3CI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boon_maae_2 = table_classification_fold(metrics_boon[\"maae\"], dimension=2)\n",
    "\n",
    "boon_maae_2.to_latex(\"{}/acc-maae-boon-fold-2.tex\".format(path_table),\n",
    "                     caption=\"Accuracy in Classification, with loss MAAE\"\\\n",
    "                     \", on each fold cross-validation, for Dataset 1.\",\n",
    "                     label=\"table:acc-maae-boon-fold-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZQpKo0iA3CK"
   },
   "source": [
    "> Table 7: Accuracy in Classification, with loss `MAAE`, on each fold cross-validation, for Dataset 1<a name=\"table:accuracy-ae-l2-d1-fold\"></a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T01:54:34.161531Z",
     "start_time": "2020-03-22T01:54:34.148992Z"
    },
    "colab_type": "text",
    "id": "MQHXdemhA3CL"
   },
   "source": [
    "In the original paper we observe similar differences between the two functions, the results for AE-CDNN-MAAE are smoothly better for most classifiers, but considering gaussian\\_nb, for example, the function AE-CDNN-MAAE acquired much better results comparing with AE-CDNN-MAE. Although the results in original paper also have few variations for the classifiers svm\\_linear, svm\\_radial and multi\\_layer we had no variance in these classifers for function AE-CDNN-MAAE.\n",
    "\n",
    "In the second dataset, in Tables below, when analyzing by fold we have that results are worse than those reported by the authors. However, the results is consistent with the hypothesis during the process, there was no feature learning. Also given the balance of this second dataset, we have that all methods do not present a better result than the random chance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.288194Z",
     "start_time": "2020-04-22T05:29:16.389Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "M3hjjGkDA3CN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chbmit_mae_2 = table_classification_fold(metrics_chbmit[\"mae\"], dimension=2)\n",
    "\n",
    "chbmit_mae_2.to_latex(\"{}/acc-mae-chbmit-fold-2.tex\".format(path_table),\n",
    "                     caption=\"Accuracy in Classification, with loss MAE\"\\\n",
    "                     \", on each fold cross-validation, for Dataset 2.\",\n",
    "                     label=\"table:acc-mae-chbmit-fold-2\")\n",
    "\n",
    "chbmit_mae_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T04:10:47.542283Z",
     "start_time": "2020-03-30T04:10:47.536711Z"
    },
    "colab_type": "text",
    "id": "jUCylFWXA3CR"
   },
   "source": [
    "> Table 8: Accuracy in Classification, with loss `MAE`, on each fold cross-validation, for Dataset 2<a name=\"table:accuracy-ae-l1-d2-fold\"></a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.288646Z",
     "start_time": "2020-04-22T05:29:16.398Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "klQ-X3IeA3CS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chbmit_maae_2 = table_classification_fold(metrics_chbmit[\"maae\"], dimension=2)\n",
    "\n",
    "chbmit_maae_2.to_latex(\"{}/acc-maae-chbmit-fold-2.tex\".format(path_table),\n",
    "                       caption=\"Accuracy in Classification, with loss MAAE\"\\\n",
    "                       \", on each fold cross-validation, for Dataset 2.\",\n",
    "                       label=\"table:acc-maae-chbmit-fold-2\")\n",
    "\n",
    "chbmit_maae_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzxpbhKNA3CU"
   },
   "source": [
    "> Table 9: Accuracy in Classification, with loss `MAAE`, on each fold cross-validation, for Dataset 2<a name=\"table:accuracy-ae-l2-d2-fold\"></a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NAnAiZK_A3CV"
   },
   "source": [
    "\n",
    "When analyzing the reduced values by class, specifically with $m = 4$ we have $3$ of the $4$ attributes are $0$, in the best scenario, indicating that there was no learning in Auto Encoder to distinguish the behavior by class. This bad representation of latent space occurs regardless of the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.289102Z",
     "start_time": "2020-04-22T05:29:16.406Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1BvhT8CrA3CV"
   },
   "outputs": [],
   "source": [
    "fig_feat_distri = plot_feature_distribution(PATH_BOON, 4,\n",
    "                                            names=[\"AE-CDNN-MAE\",\n",
    "                                                   \"AE-CDNN-MAAE\"])\n",
    "\n",
    "plt.savefig(\"{}/feature_distribution_4.pdf\".format(path_figure),\n",
    "            bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9zBMN_amA3CY"
   },
   "source": [
    "> Figure 8: Feature Distribution of AE-CDNN-MAE and AE-CDNN-MAAE, with $m=4$, in the first dataset. <a name=\"fig:feature-\"></a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T04:00:42.563500Z",
     "start_time": "2020-03-22T04:00:42.554654Z"
    },
    "colab_type": "text",
    "id": "3kKRArbhA3CZ"
   },
   "source": [
    "When we analyze the behavior of the loss functions at the epoch in the first dataset, we have that these do not have a parallel with those reported by the original author. In addition, numerically in the second function MAAE the values also do not present an adequate dimension with that originally reported. Consequently, we also have an indication that in the MAAE function there was not an adequate generalization in the validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.289557Z",
     "start_time": "2020-04-22T05:29:16.415Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "H9XkWrIJA3Ca"
   },
   "outputs": [],
   "source": [
    "history_mae_4 = read_history_model(PATH_BOON, \"mae\", 4)\n",
    "history_maae_4 = read_history_model(PATH_BOON, \"maae\", 4)\n",
    "\n",
    "fig_change_loss = plot_change_loss(history_mae_4, history_maae_4,\n",
    "                                  [\"AE-CDNN-MAE\", \"AE-CDNN-MAAE\"])\n",
    "\n",
    "plt.savefig(\"{}/change_loss_mae_maae.pdf\".format(path_figure),\n",
    "            bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XkZXTE4oA3Ce"
   },
   "source": [
    "> Figure 9: Change of loss function of AE-CDNN-MAE and AE-CDNN-MAAE, in the first dataset, with $m=4$ <a name=\"fig:loss-change-4\"></a>.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePaZ9w6GA3Cg"
   },
   "source": [
    "Even assuming that the author used the MAPE loss function, we still do not obtain an adequate result in loss at the epoch, as show the Figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.290019Z",
     "start_time": "2020-04-22T05:29:16.424Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "qyTvxeS5A3Cg"
   },
   "outputs": [],
   "source": [
    "history_mape_4 = read_history_model(PATH_BOON, \"mape\", 4)\n",
    "\n",
    "fig_change_loss = plot_change_loss(history_mae_4, history_mape_4,\n",
    "                                   names=[\"AE-CDNN-MAE\", \"AE-CDNN-MAPE\"])\n",
    "\n",
    "plt.savefig(\"{}/change_loss_mae_mape.pdf\".format(path_figure),\n",
    "            bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T04:52:11.723900Z",
     "start_time": "2020-03-30T04:52:11.718397Z"
    },
    "colab_type": "text",
    "id": "M-GiyJRpA3Cl"
   },
   "source": [
    "> Figure 10: Change of loss function of AE-CDNN-MAE and AE-CDNN-MAPE, in the first dataset, with $m=4$ <a name=\"fig:loss-change-4\"></a>.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HU3eZ81nA3Cm"
   },
   "source": [
    "These differences also occur in the establishment in the baseline methods, indicating that there is some cut in the training set that was not included in this modeling, given the lack of information in the article. In Baseline Figure we observe similar average accuracy between AE-CDNN-MAE, AE-CDNN-MAAE, PCA and SRP for both datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.290475Z",
     "start_time": "2020-04-22T05:29:16.433Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jvjoe3SPA3Cm"
   },
   "outputs": [],
   "source": [
    "fig_avg_acc_base = plot_average_metric_baseline(metrics_boon[\"mae\"], \n",
    "                                                metrics_boon[\"mape\"],\n",
    "                                                metrics_boon[\"pca\"], \n",
    "                                                metrics_boon[\"srp\"],\n",
    "                                                metrics_chbmit[\"mae\"], \n",
    "                                                metrics_chbmit[\"mape\"],\n",
    "                                                metrics_chbmit[\"pca\"], \n",
    "                                                metrics_chbmit[\"srp\"],\n",
    "                                                name=[\"AE-CDNN-MAE\",\n",
    "                                                      \"AE-CDNN-MAAE\",\n",
    "                                                      \"PCA\", \"SRP\"])\n",
    "\n",
    "\n",
    "plt.savefig(\"{}/baseline_methods.pdf\".format(path_figure),\n",
    "            bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_gFRf4iA3Cp"
   },
   "source": [
    "> Figure 11: Comparison of accuracy for different loss functions (`AE-CDNN-MAE`, `AE-CDNN-MAAE`), and also with baseline (`PCA`, `SRP`) <a name=\"fig:baseline\"></a>.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gV3U4B5tA3Cp"
   },
   "source": [
    "The same is observed in the original article, as well as a similar behavior, but the average accuracy obtained for Dataset 1 are significantly higher than those obtained by our reproduction, as shown in the Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.290964Z",
     "start_time": "2020-04-22T05:29:16.442Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jMYeDJ7KA3Cr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_boon_cv_10 = run_classification(path_dataset=PATH_BOON,\n",
    "                                        name_type=\"mae\",\n",
    "                                        range_values=[16, 32],\n",
    "                                        cross_values=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.291400Z",
     "start_time": "2020-04-22T05:29:16.450Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yVm6sHCkA3Cv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_boon_10 = table_classification_dimension(metrics_boon_cv_10,\n",
    "                                             metric=\"accuracy\")\n",
    "\n",
    "\n",
    "acc_boon_10.to_latex(\"{}/metrics_boon_cv_10.tex\".format(path_table),\n",
    "                     caption=\"Accuracy in Classification, \"\n",
    "                     \"in the first dataset with $CV=10$.\",\n",
    "                     label=\"metrics_boon_cv_10\")\n",
    "\n",
    "acc_boon_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzlwkCKYA3C0"
   },
   "source": [
    "When we analyze the result assuming a $10$-fold, we have an increase in the accuracy values for the first dataset, however, still below that reported by the author.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_v30d7XA3C1"
   },
   "source": [
    "## 8.2. Extension of the values reported by the original author.\n",
    "\n",
    "In Precision, we realize that one of the most precise and specific method was the Gaussian Naive Bayesian; however, when analyzing the behavior in the Sensitivity metric, we do not have a satisfactory result. This indicates that the method pinpoints true negatives rather than true positives. If treated from a medical field, this result is worrying. The cases that the method indicates are true positives; however, this method misses many cases.\n",
    "\n",
    "We also analyze that we cannot consider Support Vector Machine (Linear and Radial) or Multi-Layer results with the lowest $m$. The result in specificity indicates that the method behaves unwanted, possibly indicating all values as true positives. This rule burdens the medical system because further detection of the seizure requires further investigation for a complete diagnosis of the disease.\n",
    "\n",
    "By our method, we note that the three metrics indicate that a progression in the number of features generates an improvement in seizure detection. Similar behavior is observed in Multi-Layer, only for Accuracy and Sensitivity, in this case, a beneficial behavior for the application. No trend was observed in the other methods. The average of the methods does not exceed our Ensemble method in almost any scenario. \n",
    "\n",
    "\n",
    "### 8.3. Precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.291863Z",
     "start_time": "2020-04-22T05:29:16.459Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "NaXi7gofnOVk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision_mae_d1, pre_mae_d1_style = table_export_latex(path_save=path_table,\n",
    "                                                        dataset=metrics_boon,\n",
    "                                                        name_type=\"mae\",\n",
    "                                                        metric=\"precision\",\n",
    "                                                        name_dataset=\"boon\",\n",
    "                                                        original=False,\n",
    "                                                        proposed=False)\n",
    "pre_mae_d1_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.292320Z",
     "start_time": "2020-04-22T05:29:16.464Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "y-RWoYJWA3C4"
   },
   "outputs": [],
   "source": [
    "precision_maae_d1, pre_maae_d1_style = table_export_latex(path_save=path_table,\n",
    "                                                          dataset=metrics_boon,\n",
    "                                                          name_type=\"maae\",\n",
    "                                                          metric=\"precision\",\n",
    "                                                          name_dataset=\"boon\",\n",
    "                                                          original=False,\n",
    "                                                          proposed=False)\n",
    "pre_maae_d1_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T19:10:11.646756Z",
     "start_time": "2020-04-01T19:10:11.627529Z"
    },
    "colab_type": "text",
    "id": "ru0UIj_OA3DD"
   },
   "source": [
    "In the first dataset, when we analyze the accuracy we have that the naive bayes Gaussian classifier presents a drop of ($ 40 \\%, 23 \\% $, for first and second loss respectively) if compared to the accuracy. The average difference, in precision minus accuracy, is $6\\%$, indicating that the precision metric achieves slightly higher results on average in the samples. The k\\_neighbors classifier is the classifier, in the first loss function, that has the least average difference in results, while the svm\\_linear method shows the same result for the second loss set. At the other end, we have the largest variation in both gaussian\\_nb data sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.292762Z",
     "start_time": "2020-04-22T05:29:16.471Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "PsDo7Yy8A3DD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision_mae_d2, pre_mae_d2_style = table_export_latex(path_save=path_table,\n",
    "                                                        dataset=metrics_chbmit,\n",
    "                                                        name_type=\"mae\",\n",
    "                                                        metric=\"precision\",\n",
    "                                                        name_dataset=\"chbmit\",\n",
    "                                                        original=False,\n",
    "                                                        proposed=False)\n",
    "pre_mae_d2_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.293247Z",
     "start_time": "2020-04-22T05:29:16.476Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gz50s6b8A3DH"
   },
   "outputs": [],
   "source": [
    "precision_maae_d2, pre_maae_d2_style = table_export_latex(path_save=path_table,\n",
    "                                                          dataset=metrics_chbmit,\n",
    "                                                          name_type=\"maae\",\n",
    "                                                          metric=\"precision\",\n",
    "                                                          name_dataset=\"chbmit\",\n",
    "                                                          original=False, \n",
    "                                                          proposed=False)\n",
    "pre_maae_d2_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qVpDDzuVA3DK"
   },
   "source": [
    "\n",
    "Meanwhile, in the second set of data, generated by the two loss functions, the difference between precision and accuracy is greater in the smallest dimensions, while the values are more stable, and close to the accuracy values in the largest dimensions. Such stability behavior is also observed in the absolute values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RSE9p3m_A3DK"
   },
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gm0kxEt4A3DL"
   },
   "source": [
    "### 8.2.2 Specificity and Sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eKoGMvHSA3DL"
   },
   "source": [
    "When we analyze the specificity, we have that the SVM method, with different kernels, cannot obtain a separation of the hyperspaces of the attributes to distinguish the non-schizoid events. In this way, we have that the classifier cannot distinguish when the person is without epileptic attack. From a medical point of view, there are not so many implications for this, since the weighting of importance is inclined to detect true positives. The SVM sensitivity for these cases, in high dimensions (above $ 32 $) presents reasonable values, approximately $70\\%$ in the worst scenarios. In general, the panorama of the accumulated sensitivity indicates that the worst classifiers, regardless of the number of dimensions, are the Gaussian naive bayes, and the __K-neighbors__ for high dimensions. The ensemble classifier has average cumulative sensitivity ($ 71 \\% $ in the worst case scenario), with the exception of lower case scenarios $ 2 $.\n",
    "\n",
    "The performance of the Gaussian classifier may be related to the fact that the inputs are highly dependent on each other, thus violating the method's premise of independence. In the case of the k-neighbors classifier, given the presence of the values $ 0 $ in various dimensions, as shown previously, which can affect the distance assumptions necessary for the method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:35:30.848473Z",
     "start_time": "2020-04-22T05:35:30.227812Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tGuuosw-ot-7"
   },
   "outputs": [],
   "source": [
    "spe_mae_d1, spe_mae_d1_style = table_export_latex(path_save=path_table,\n",
    "                                                  dataset=metrics_boon,\n",
    "                                                  name_type=\"mae\",\n",
    "                                                  metric=\"specificity\",\n",
    "                                                  name_dataset=\"boon\",\n",
    "                                                  original=False, \n",
    "                                                  proposed=False)\n",
    "spe_mae_d1_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:35:30.879427Z",
     "start_time": "2020-04-22T05:35:30.854835Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jvBGlZooo8f2"
   },
   "outputs": [],
   "source": [
    "spe_maae_d1, spe_maae_d1_style = table_export_latex(path_save=path_table,\n",
    "                                                    dataset=metrics_boon,\n",
    "                                                    name_type=\"maae\",\n",
    "                                                    metric=\"specificity\",\n",
    "                                                    name_dataset=\"boon\",\n",
    "                                                    original=False, \n",
    "                                                    proposed=False)\n",
    "spe_maae_d1_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:35:31.160068Z",
     "start_time": "2020-04-22T05:35:31.095654Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BX23gF4EA3DU"
   },
   "outputs": [],
   "source": [
    "spe_mae_d2, spe_mae_d2_style = table_export_latex(path_save=path_table,\n",
    "                                                  dataset=metrics_chbmit,\n",
    "                                                  name_type=\"mae\",\n",
    "                                                  metric=\"specificity\",\n",
    "                                                  name_dataset=\"chbmit\",\n",
    "                                                  original=False, \n",
    "                                                  proposed=False)\n",
    "spe_mae_d2_style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:35:33.705921Z",
     "start_time": "2020-04-22T05:35:33.680099Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UzCcY5whA3DW"
   },
   "outputs": [],
   "source": [
    "spe_maae_d2, spe_maae_d2_style = table_export_latex(path_save=path_table,\n",
    "                                                    dataset=metrics_chbmit,\n",
    "                                                    name_type=\"maae\",\n",
    "                                                    metric=\"specificity\",\n",
    "                                                    name_dataset=\"chbmit\",\n",
    "                                                    original=False, \n",
    "                                                    proposed=False)\n",
    "spe_maae_d2_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tf9uvqNuA3Da"
   },
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.295540Z",
     "start_time": "2020-04-22T05:29:16.515Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "S16bF7_yA3Da"
   },
   "outputs": [],
   "source": [
    "sen_mae_d1, sen_mae_d1_style = table_export_latex(path_save=path_table,\n",
    "                                                  dataset=metrics_boon,\n",
    "                                                  name_type=\"mae\",\n",
    "                                                  metric=\"sensitivity\",\n",
    "                                                  name_dataset=\"boon\",\n",
    "                                                  original=False, \n",
    "                                                  proposed=False)\n",
    "sen_mae_d1_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.295977Z",
     "start_time": "2020-04-22T05:29:16.521Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pNiM3G7PA3Dd"
   },
   "outputs": [],
   "source": [
    "sen_maae_d1, sen_maae_d1_style = table_export_latex(path_save=path_table,\n",
    "                                                    dataset=metrics_boon,\n",
    "                                                    name_type=\"maae\",\n",
    "                                                    metric=\"sensitivity\",\n",
    "                                                    name_dataset=\"boon\",\n",
    "                                                    original=False, \n",
    "                                                    proposed=False)\n",
    "sen_maae_d1_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.296479Z",
     "start_time": "2020-04-22T05:29:16.527Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-qwKCjxVA3Dh"
   },
   "outputs": [],
   "source": [
    "sen_mae_d2, sen_mae_d2_style = table_export_latex(path_save=path_table,\n",
    "                                                  dataset=metrics_chbmit,\n",
    "                                                  name_type=\"mae\",\n",
    "                                                  metric=\"sensitivity\",\n",
    "                                                  name_dataset=\"chbmit\",\n",
    "                                                  original=False, \n",
    "                                                  proposed=False)\n",
    "sen_mae_d2_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.296942Z",
     "start_time": "2020-04-22T05:29:16.533Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "59MHXB_wA3Do"
   },
   "outputs": [],
   "source": [
    "sen_maae_d2, sen_maae_d2_style = table_export_latex(path_save=path_table,\n",
    "                                                    dataset=metrics_chbmit,\n",
    "                                                    name_type=\"maae\",\n",
    "                                                    metric=\"sensitivity\",\n",
    "                                                    name_dataset=\"chbmit\",\n",
    "                                                    original=False, \n",
    "                                                    proposed=False)\n",
    "sen_maae_d2_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UApZlv5kA3Dr"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mbf2B8i4A3Dr"
   },
   "source": [
    "### 8.2.2 F-measure and ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T21:02:41.665899Z",
     "start_time": "2020-04-01T21:02:41.458660Z"
    },
    "colab_type": "text",
    "id": "_3NJ2z5XA3Ds"
   },
   "source": [
    "When analyzing the behavior of the methods for the reason of the metrics of $ F-measure $ and $ ROC-AUC $ we have that in the first data set, the SVM and multi\\_layer methods present the best results. At the other end, we have the appearance with the naive bayes and $k$ neighbor methods.\n",
    "\n",
    "We analyze the behavior of the F-measure. The relationship between sensitivity and precision is captured by this measure, as the gaussian\\_nb, svm\\_linear, k\\_neighbors methods did not obtain good results, which is coherent with the accuracy result. The measures generally show close results with each other. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.297401Z",
     "start_time": "2020-04-22T05:29:16.546Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TS8QyYEsp7wO"
   },
   "outputs": [],
   "source": [
    "fmea_mae_d1, fmea_mae_d1_style = table_export_latex(path_save=path_table,\n",
    "                                                  dataset=metrics_boon,\n",
    "                                                  name_type=\"mae\",\n",
    "                                                  metric=\"f-measure\",\n",
    "                                                  name_dataset=\"boon\",\n",
    "                                                  original=False, \n",
    "                                                  proposed=False)\n",
    "fmea_mae_d1_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.297851Z",
     "start_time": "2020-04-22T05:29:16.552Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "F2xlQ3f1A3Dy"
   },
   "outputs": [],
   "source": [
    "fmea_maae_d1, fmea_maae_d1_style = table_export_latex(path_save=path_table,\n",
    "                                                  dataset=metrics_boon,\n",
    "                                                  name_type=\"maae\",\n",
    "                                                  metric=\"f-measure\",\n",
    "                                                  name_dataset=\"boon\",\n",
    "                                                  original=False, \n",
    "                                                  proposed=False)\n",
    "fmea_maae_d1_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.298305Z",
     "start_time": "2020-04-22T05:29:16.558Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "It--bvlQA3D2"
   },
   "outputs": [],
   "source": [
    "fmea_mae_d2, fmea_mae_d2_style = table_export_latex(path_save=path_table,\n",
    "                                                  dataset=metrics_chbmit,\n",
    "                                                  name_type=\"mae\",\n",
    "                                                  metric=\"f-measure\",\n",
    "                                                  name_dataset=\"chbmit\",\n",
    "                                                  original=False, \n",
    "                                                  proposed=False)\n",
    "fmea_mae_d2_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.298733Z",
     "start_time": "2020-04-22T05:29:16.564Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8stU2jgPA3D5"
   },
   "outputs": [],
   "source": [
    "fmea_maae_d2, fmea_maae_d2_style = table_export_latex(path_save=path_table,\n",
    "                                                  dataset=metrics_chbmit,\n",
    "                                                  name_type=\"maae\",\n",
    "                                                  metric=\"f-measure\",\n",
    "                                                  name_dataset=\"chbmit\",\n",
    "                                                  original=False, \n",
    "                                                  proposed=False)\n",
    "fmea_maae_d2_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hxAzZpBdA3D-"
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.299200Z",
     "start_time": "2020-04-22T05:29:16.572Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Qek7KUhOA3D-"
   },
   "outputs": [],
   "source": [
    "roc_mae_d1, roc_mae_d1_style = table_export_latex(path_save=path_table,\n",
    "                                                  dataset=metrics_boon,\n",
    "                                                  name_type=\"mae\",\n",
    "                                                  metric=\"roc-auc\",\n",
    "                                                  name_dataset=\"boon\",\n",
    "                                                  original=False, \n",
    "                                                  proposed=False)\n",
    "roc_mae_d1_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.299637Z",
     "start_time": "2020-04-22T05:29:16.579Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GV5-ojc7A3ED"
   },
   "outputs": [],
   "source": [
    "roc_maae_d1, roc_maae_d1_style = table_export_latex(path_save=path_table,\n",
    "                                                    dataset=metrics_boon,\n",
    "                                                    name_type=\"maae\",\n",
    "                                                    metric=\"roc-auc\",\n",
    "                                                    name_dataset=\"boon\",\n",
    "                                                    original=False, \n",
    "                                                    proposed=False)\n",
    "roc_maae_d1_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.300133Z",
     "start_time": "2020-04-22T05:29:16.585Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yOzYZ_OTA3EH"
   },
   "outputs": [],
   "source": [
    "roc_mae_d2, roc_mae_d2_style = table_export_latex(path_save=path_table,\n",
    "                                                  dataset=metrics_chbmit,\n",
    "                                                  name_type=\"mae\",\n",
    "                                                  metric=\"roc-auc\",\n",
    "                                                  name_dataset=\"chbmit\",\n",
    "                                                  original=False, \n",
    "                                                  proposed=False)\n",
    "roc_mae_d2_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:29:24.300609Z",
     "start_time": "2020-04-22T05:29:16.591Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yffgQV7KA3EL"
   },
   "outputs": [],
   "source": [
    "roc_maae_d2, roc_maae_d2_style = table_export_latex(path_save=path_table,\n",
    "                                                  dataset=metrics_chbmit,\n",
    "                                                  name_type=\"maae\",\n",
    "                                                  metric=\"roc-auc\",\n",
    "                                                  name_dataset=\"chbmit\",\n",
    "                                                  original=False, \n",
    "                                                  proposed=False)\n",
    "roc_maae_d2_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RF7BnuOKA3EO"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 9. Conclusion <a name=\"concl\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGudmXoAA3EP"
   },
   "source": [
    "In this article, we re-implemented the approach proposed in  <a id=\"ref-33\" href=\"#cite-WenZha\">Wen and Zhang 2018</a> and propose the use of a different classifier. This classification approach, based on deep learning for detecting epileptic seizures using EGG had not been explored previously. We adopted a Auto-Enconder that allowed us to construct a smaller representation space. Among the variety of metrics, using the ensemble method results in better ROC-AUC results.\n",
    "\n",
    "The original authors left some gaps that made it impossible to fully reproduce their obtained results. For example, the lack of information about the neural classifier used in the last sub-section, about the sampling process of the first and second data sets, and the number of times or batch size. Consequently, the results obtained can be considered at most a replication.\n",
    "\n",
    "As a second contribution, the developed codes can be easily ported to other tasks. Moreover, it could be used to evaluate other variants of the neural network architecture, techniques for classifying the signals, data augmentation, among other possibilities.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqW3WF7sA3EQ"
   },
   "source": [
    "<!--bibtex \n",
    "\n",
    "@Article{WenZha:2018,\n",
    "    author = {Wen, Tingxi and Zhang, Zhongnan},\n",
    "    year = {2018},\n",
    "    month = {05},\n",
    "    pages = {1-1},\n",
    "    title = {Deep Convolution Neural Network and Autoencoders-based Unsupervised Feature Learning of EEG Signals},\n",
    "    volume = {PP},\n",
    "    journal = {IEEE Access},\n",
    "    doi = {10.1109/ACCESS.2018.2833746}\n",
    "}\n",
    "\n",
    "@Article{Shoeb,\n",
    " author = {Shoeb, Ali and Guttag, John},\n",
    " title = {Application of Machine Learning to Epileptic Seizure Detection},\n",
    " booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},\n",
    " series = {ICML'10},\n",
    " year = {2010},\n",
    " isbn = {978-1-60558-907-7},\n",
    " location = {Haifa, Israel},\n",
    " pages = {975--982},\n",
    " numpages = {8},\n",
    " url = {http://dl.acm.org/citation.cfm?id=3104322.3104446},\n",
    " acmid = {3104446},\n",
    " publisher = {Omnipress},\n",
    " address = {USA},\n",
    "} \n",
    "\n",
    "@Article{tensorflow,\n",
    "  title={Tensorflow: A system for large-scale machine learning},\n",
    "  author={Abadi, Mart{\\'\\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},\n",
    "  booktitle={12th $\\{$USENIX$\\}$ Symposium on Operating Systems Design and Implementation ($\\{$OSDI$\\}$ 16)},\n",
    "  pages={265--283},\n",
    "  year={2016}\n",
    "}\n",
    "\n",
    "@Article{how,\n",
    "  title={How Complex is your classification problem? A survey on measuring classification complexity},\n",
    "  author={Lorena, Ana C and Garcia, Lu{\\'\\i}s PF and Lehmann, Jens and Souto, Marcilio CP and Ho, Tin K},\n",
    "  journal={arXiv preprint arXiv:1808.03591},\n",
    "  year={2018}\n",
    "}\n",
    "\n",
    "@Article{andrzejak,\n",
    "    author = {G. Andrzejak, Ralph and Lehnertz, Klaus and Mormann, Florian and Rieke, Christoph and David, Peter and Elger, Christian},\n",
    "    year = {2002},\n",
    "    month = {01},\n",
    "    pages = {061907},\n",
    "    title = {Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state},\n",
    "    volume = {64},\n",
    "    journal = {Physical review. E, Statistical, nonlinear, and soft matter physics},\n",
    "    doi = {10.1103/PhysRevE.64.061907}\n",
    "}\n",
    "\n",
    "@Article{kamath2015analysis,\n",
    "  title={Analysis of EEG dynamics in epileptic patients and healthy subjects using Hilbert transform scatter plots},\n",
    "  author={Kamath, Chandrakar},\n",
    "  journal={Open Access Library Journal},\n",
    "  volume={2},\n",
    "  number={1},\n",
    "  pages={1},\n",
    "  year={2015},\n",
    "  publisher={Scientific Research Publishing}\n",
    "}\n",
    "\n",
    "\n",
    "@Article{chollet2018keras,\n",
    "  title={Keras: The python deep learning library},\n",
    "  author={Chollet, Fran{\\c{c}}ois and others},\n",
    "  journal={Astrophysics Source Code Library},\n",
    "  year={2018}\n",
    "}\n",
    "\n",
    "@Article{benavoli2017time,\n",
    "  title={Time for a change: a tutorial for comparing multiple classifiers through Bayesian analysis},\n",
    "  author={Benavoli, Alessio and Corani, Giorgio and Dem{\\v{s}}ar, Janez and Zaffalon, Marco},\n",
    "  journal={The Journal of Machine Learning Research},\n",
    "  volume={18},\n",
    "  number={1},\n",
    "  pages={2653--2688},\n",
    "  year={2017},\n",
    "  publisher={JMLR. org}\n",
    "}\n",
    "\n",
    "@Article{Fuente:2019,\n",
    "  author = {la Fuente, Alfredo De and Aduviri, Robert},\n",
    "  title = {{[Re] Variational Sparse Coding}},\n",
    "  journal = {ReScience C},\n",
    "  year = {2019},\n",
    "  month = may,\n",
    "  volume = {5},\n",
    "  number = {2},\n",
    "  pages = {{\\#2}},\n",
    "  doi = {10.5281/zenodo.3161734},\n",
    "  url = {https://zenodo.org/record/3161734/files/Article.pdf},\n",
    "  code_url = {https://github.com/Alfo5123/Variational-Sparse-Coding},\n",
    "  code_doi = {10.5281/zenodo.2657330},\n",
    "  data_url = {},\n",
    "  data_doi = {},\n",
    "  review_url = {https://github.com/reproducibility-challenge/iclr_2019/pull/146},\n",
    "  type = {Replication},\n",
    "  language = {Python},\n",
    "  domain = {Machine Learning},\n",
    "  keywords = {generative models, variational autoencoders, sparse coding}\n",
    "}\n",
    "\n",
    "\n",
    "@Article{saab2005system,\n",
    "  title={A system to detect the onset of epileptic seizures in scalp EEG},\n",
    "  author={Saab, ME and Gotman, Jean},\n",
    "  journal={Clinical Neurophysiology},\n",
    "  volume={116},\n",
    "  number={2},\n",
    "  pages={427--442},\n",
    "  year={2005},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "\n",
    "@Article{kuhlmann2009seizure,\n",
    "  title={Seizure detection using seizure probability estimation: Comparison of features used to detect seizures},\n",
    "  author={Kuhlmann, Levin and Burkitt, Anthony N and Cook, Mark J and Fuller, Karen and Grayden, David B and Seiderer, Linda and Mareels, Iven MY},\n",
    "  journal={Annals of biomedical engineering},\n",
    "  volume={37},\n",
    "  number={10},\n",
    "  pages={2129--2145},\n",
    "  year={2009},\n",
    "  publisher={Springer}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "@Article{shoeb2004patient,\n",
    "  title={Patient-specific seizure onset detection},\n",
    "  author={Shoeb, Ali and Edwards, Herman and Connolly, Jack and Bourgeois, Blaise and Treves, S Ted and Guttag, John},\n",
    "  journal={Epilepsy \\& Behavior},\n",
    "  volume={5},\n",
    "  number={4},\n",
    "  pages={483--498},\n",
    "  year={2004},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "@Article{shoeb2011machine,\n",
    "  title={A machine-learning algorithm for detecting seizure termination in scalp EEG},\n",
    "  author={Shoeb, Ali and Kharbouch, Alaa and Soegaard, Jacqueline and Schachter, Steven and Guttag, John},\n",
    "  journal={Epilepsy \\& Behavior},\n",
    "  volume={22},\n",
    "  pages={S36--S43},\n",
    "  year={2011},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "\n",
    "@Article{ullah2018automated,\n",
    "  title={An automated system for epilepsy detection using EEG brain signals based on deep learning approach},\n",
    "  author={Ullah, Ihsan and Hussain, Muhammad and Aboalsamh, Hatim and others},\n",
    "  journal={Expert Systems with Applications},\n",
    "  volume={107},\n",
    "  pages={61--71},\n",
    "  year={2018},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "@Article{chua2011application,\n",
    "  title={Application of higher order spectra to identify epileptic EEG},\n",
    "  author={Chua, Kuang Chua and Chandran, Vinod and Acharya, U Rajendra and Lim, Choo Min},\n",
    "  journal={Journal of medical systems},\n",
    "  volume={35},\n",
    "  number={6},\n",
    "  pages={1563--1571},\n",
    "  year={2011},\n",
    "  publisher={Springer}\n",
    "}\n",
    "\n",
    "@Article{nicolaou2012detection,\n",
    "  title={Detection of epileptic electroencephalogram based on permutation entropy and support vector machines},\n",
    "  author={Nicolaou, Nicoletta and Georgiou, Julius},\n",
    "  journal={Expert Systems with Applications},\n",
    "  volume={39},\n",
    "  number={1},\n",
    "  pages={202--209},\n",
    "  year={2012},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "\n",
    "@Article{xun2016detecting,\n",
    "  title={Detecting epileptic seizures with electroencephalogram via a context-learning model},\n",
    "  author={Xun, Guangxu and Jia, Xiaowei and Zhang, Aidong},\n",
    "  journal={BMC medical informatics and decision making},\n",
    "  volume={16},\n",
    "  number={2},\n",
    "  pages={70},\n",
    "  year={2016},\n",
    "  publisher={BioMed Central}\n",
    "}\n",
    "\n",
    "@Article{acharya2018deep,\n",
    "  title={Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals},\n",
    "  author={Acharya, U Rajendra and Oh, Shu Lih and Hagiwara, Yuki and Tan, Jen Hong and Adeli, Hojjat},\n",
    "  journal={Computers in biology and medicine},\n",
    "  volume={100},\n",
    "  pages={270--278},\n",
    "  year={2018},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "\n",
    "@Article{emami2019autoencoding,\n",
    "  title={Autoencoding of long-term scalp electroencephalogram to detect epileptic seizure for diagnosis support system},\n",
    "  author={Emami, Ali and Kunii, Naoto and Matsuo, Takeshi and Shinozaki, Takashi and Kawai, Kensuke and Takahashi, Hirokazu},\n",
    "  journal={Computers in biology and medicine},\n",
    "  year={2019},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "@Article{hussein2018epileptic,\n",
    "  title={Epileptic seizure detection: A deep learning approach},\n",
    "  author={Hussein, Ramy and Palangi, Hamid and Ward, Rabab and Wang, Z Jane},\n",
    "  journal={arXiv preprint arXiv:1803.09848},\n",
    "  year={2018}\n",
    "}\n",
    "\n",
    "@Article{roy2019deep,\n",
    "  title={Deep learning-based electroencephalography analysis: a systematic review},\n",
    "  author={Roy, Yannick and Banville, Hubert and Albuquerque, Isabela and Gramfort, Alexandre and Falk, Tiago H and Faubert, Jocelyn},\n",
    "  journal={Journal of neural engineering},\n",
    "  year={2019},\n",
    "  publisher={IOP Publishing}\n",
    "}\n",
    "\n",
    "@article{most_commum:2002,\n",
    "author = {Reynolds, E. H.},\n",
    "title = {The ILAE/IBE/WHO Epilepsy Global Campaign History},\n",
    "journal = {Epilepsia},\n",
    "volume = {43},\n",
    "number = {s6},\n",
    "pages = {9-11},\n",
    "doi = {10.1046/j.1528-1157.43.s.6.5.x},\n",
    "url = {https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1528-1157.43.s.6.5.x},\n",
    "eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1046/j.1528-1157.43.s.6.5.x},\n",
    "year = {2002}\n",
    "}\n",
    "\n",
    "@article{global-epilepsy:2019,\n",
    "title = \"Global, regional, and national burden of epilepsy, 1990–2016: a systematic analysis for the Global Burden of Disease Study 2016\",\n",
    "journal = \"The Lancet Neurology\",\n",
    "volume = \"18\",\n",
    "number = \"4\",\n",
    "pages = \"357 - 375\",\n",
    "year = \"2019\",\n",
    "issn = \"1474-4422\",\n",
    "doi = \"https://doi.org/10.1016/S1474-4422(18)30454-X\",\n",
    "url = \"http://www.sciencedirect.com/science/article/pii/S147444221830454X\",\n",
    "author = \"Ettore Beghi et. al\",\n",
    "}\n",
    "\n",
    "@article{Epilepsia:2010,\n",
    "author = {Ngugi, Anthony K. and Bottomley, Christian and Kleinschmidt, Immo and Sander, Josemir W. and Newton, Charles R.},\n",
    "title = {Estimation of the burden of active and life-time epilepsy: A meta-analytic approach},\n",
    "journal = {Epilepsia},\n",
    "volume = {51},\n",
    "number = {5},\n",
    "pages = {883-890},\n",
    "keywords = {Epilepsy, Prevalence, Burden, Meta-analysis},\n",
    "doi = {10.1111/j.1528-1167.2009.02481.x},\n",
    "url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1528-1167.2009.02481.x},\n",
    "eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1528-1167.2009.02481.x},\n",
    "year = {2010}\n",
    "}\n",
    "\n",
    "\n",
    "@article{stafstrom2015seizures,\n",
    "  title={Seizures and epilepsy: an overview for neuroscientists},\n",
    "  author={Stafstrom, Carl E and Carmant, Lionel},\n",
    "  journal={Cold Spring Harbor perspectives in medicine},\n",
    "  volume={5},\n",
    "  number={6},\n",
    "  pages={a022426},\n",
    "  year={2015},\n",
    "  publisher={Cold Spring Harbor Laboratory Press}\n",
    "}\n",
    "\n",
    "@article{thomas2011confronting,\n",
    "  title={Confronting the stigma of epilepsy},\n",
    "  author={Thomas, Sanjeev V and Nair, Aparna},\n",
    "  journal={Annals of Indian Academy of Neurology},\n",
    "  volume={14},\n",
    "  number={3},\n",
    "  pages={158},\n",
    "  year={2011},\n",
    "  publisher={Wolters Kluwer--Medknow Publications}\n",
    "}\n",
    "\n",
    "\n",
    "@article{mollaouglu2013injuries,\n",
    "  title={Injuries in patients with epilepsy and some factors associated with injury},\n",
    "  author={MOLLAO{\\u{G}}LU, Mukadder and BOLAYIR, Ertu{\\u{g}}rul},\n",
    "  journal={N{\\\"o}ro Psikiyatri Ar{\\c{s}}ivi},\n",
    "  volume={50},\n",
    "  number={3},\n",
    "  pages={269},\n",
    "  year={2013},\n",
    "  publisher={Turkish Neuropsychiatric Society}\n",
    "}\n",
    "\n",
    "@book{niedermeyer2005electroencephalography,\n",
    "  title={Electroencephalography: basic principles, clinical applications, and related fields},\n",
    "  author={Niedermeyer, Ernst and da Silva, FH Lopes},\n",
    "  year={2005},\n",
    "  publisher={Lippincott Williams \\& Wilkins}\n",
    "}\n",
    "\n",
    "@article{puce2017review,\n",
    "  title={A review of issues related to data acquisition and analysis in EEG/MEG studies},\n",
    "  author={Puce, Aina and H{\\\"a}m{\\\"a}l{\\\"a}inen, Matti S},\n",
    "  journal={Brain sciences},\n",
    "  volume={7},\n",
    "  number={6},\n",
    "  pages={58},\n",
    "  year={2017},\n",
    "  publisher={Multidisciplinary Digital Publishing Institute}\n",
    "}\n",
    "\n",
    "@article{craik2019deep,\n",
    "  title={Deep learning for electroencephalogram (EEG) classification tasks: a review},\n",
    "  author={Craik, Alexander and He, Yongtian and Contreras-Vidal, Jose L},\n",
    "  journal={Journal of neural engineering},\n",
    "  volume={16},\n",
    "  number={3},\n",
    "  pages={031001},\n",
    "  year={2019},\n",
    "  publisher={IOP Publishing}\n",
    "}\n",
    "\n",
    "\n",
    "@article{schauwecker2012effects,\n",
    "  title={The effects of glycemic control on seizures and seizure-induced excitotoxic cell death},\n",
    "  author={Schauwecker, Paula Elyse},\n",
    "  journal={BMC neuroscience},\n",
    "  volume={13},\n",
    "  number={1},\n",
    "  pages={94},\n",
    "  year={2012},\n",
    "  publisher={BioMed Central}\n",
    "}\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQBgEWj7A3EQ"
   },
   "source": [
    "# References\n",
    "\n",
    "<a id=\"cite-WenZha\"/><sup><a href=#ref-1>[^]</a><a href=#ref-2>[^]</a><a href=#ref-13>[^]</a><a href=#ref-16>[^]</a><a href=#ref-20>[^]</a><a href=#ref-23>[^]</a><a href=#ref-24>[^]</a><a href=#ref-25>[^]</a><a href=#ref-29>[^]</a><a href=#ref-30>[^]</a><a href=#ref-33>[^]</a></sup>Wen, Tingxi and Zhang, Zhongnan. 2018. _Deep Convolution Neural Network and Autoencoders-based Unsupervised Feature Learning of EEG Signals_.\n",
    "\n",
    "\n",
    "<a id=\"cite-most_commum:2002\"/><sup><a href=#ref-1>[^]</a></sup>Reynolds, E. H.. 2002. _The ILAE/IBE/WHO Epilepsy Global Campaign History_. [URL](https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1528-1157.43.s.6.5.x)\n",
    "\n",
    "<a id=\"cite-global-epilepsy:2019\"/><sup><a href=#ref-2>[^]</a></sup>Ettore Beghi et. al. 2019. _Global, regional, and national burden of epilepsy, 1990–2016: a systematic analysis for the Global Burden of Disease Study 2016_. [URL](http://www.sciencedirect.com/science/article/pii/S147444221830454X)\n",
    "\n",
    "<a id=\"cite-Epilepsia:2010\"/><sup><a href=#ref-3>[^]</a></sup>Ngugi, Anthony K. and Bottomley, Christian and Kleinschmidt, Immo and Sander, Josemir W. and Newton, Charles R.. 2010. _Estimation of the burden of active and life-time epilepsy: A meta-analytic approach_. [URL](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1528-1167.2009.02481.x)\n",
    "\n",
    "<a id=\"cite-stafstrom2015seizures\"/><sup><a href=#ref-4>[^]</a><a href=#ref-7>[^]</a><a href=#ref-9>[^]</a></sup>Stafstrom, Carl E and Carmant, Lionel. 2015. _Seizures and epilepsy: an overview for neuroscientists_.\n",
    "\n",
    "<a id=\"cite-thomas2011confronting\"/><sup><a href=#ref-5>[^]</a></sup>Thomas, Sanjeev V and Nair, Aparna. 2011. _Confronting the stigma of epilepsy_.\n",
    "\n",
    "<a id=\"cite-mollaouglu2013injuries\"/><sup><a href=#ref-6>[^]</a></sup>MOLLAO\\u{GLU, Mukadder and BOLAYIR, Ertu\\u{grul. 2013. _Injuries in patients with epilepsy and some factors associated with injury_.\n",
    "\n",
    "<a id=\"cite-schauwecker2012effects\"/><sup><a href=#ref-8>[^]</a></sup>Schauwecker, Paula Elyse. 2012. _The effects of glycemic control on seizures and seizure-induced excitotoxic cell death_.\n",
    "\n",
    "<a id=\"cite-niedermeyer2005electroencephalography\"/><sup><a href=#ref-10>[^]</a></sup>Niedermeyer, Ernst and da Silva, FH Lopes. 2005. _Electroencephalography: basic principles, clinical applications, and related fields_.\n",
    "\n",
    "<a id=\"cite-puce2017review\"/><sup><a href=#ref-11>[^]</a></sup>Puce, Aina and H&auml;m&auml;l&auml;inen, Matti S. 2017. _A review of issues related to data acquisition and analysis in EEG/MEG studies_.\n",
    "\n",
    "<a id=\"cite-craik2019deep\"/><sup><a href=#ref-12>[^]</a></sup>Craik, Alexander and He, Yongtian and Contreras-Vidal, Jose L. 2019. _Deep learning for electroencephalogram (EEG) classification tasks: a review_.\n",
    "\n",
    "<a id=\"cite-saab2005system\"/><sup><a href=#ref-3>[^]</a></sup>Saab, ME and Gotman, Jean. 2005. _A system to detect the onset of epileptic seizures in scalp EEG_.\n",
    "\n",
    "<a id=\"cite-kuhlmann2009seizure\"/><sup><a href=#ref-4>[^]</a></sup>Kuhlmann, Levin and Burkitt, Anthony N and Cook, Mark J and Fuller, Karen and Grayden, David B and Seiderer, Linda and Mareels, Iven MY. 2009. _Seizure detection using seizure probability estimation: Comparison of features used to detect seizures_.\n",
    "\n",
    "<a id=\"cite-shoeb2004patient\"/><sup><a href=#ref-5>[^]</a></sup>Shoeb, Ali and Edwards, Herman and Connolly, Jack and Bourgeois, Blaise and Treves, S Ted and Guttag, John. 2004. _Patient-specific seizure onset detection_.\n",
    "\n",
    "<a id=\"cite-shoeb2011machine\"/><sup><a href=#ref-6>[^]</a></sup>Shoeb, Ali and Kharbouch, Alaa and Soegaard, Jacqueline and Schachter, Steven and Guttag, John. 2011. _A machine-learning algorithm for detecting seizure termination in scalp EEG_.\n",
    "\n",
    "<a id=\"cite-ullah2018automated\"/><sup><a href=#ref-7>[^]</a><a href=#ref-15>[^]</a></sup>Ullah, Ihsan and Hussain, Muhammad and Aboalsamh, Hatim and others. 2018. _An automated system for epilepsy detection using EEG brain signals based on deep learning approach_.\n",
    "\n",
    "<a id=\"cite-chua2011application\"/><sup><a href=#ref-8>[^]</a></sup>Chua, Kuang Chua and Chandran, Vinod and Acharya, U Rajendra and Lim, Choo Min. 2011. _Application of higher order spectra to identify epileptic EEG_.\n",
    "\n",
    "<a id=\"cite-nicolaou2012detection\"/><sup><a href=#ref-9>[^]</a></sup>Nicolaou, Nicoletta and Georgiou, Julius. 2012. _Detection of epileptic electroencephalogram based on permutation entropy and support vector machines_.\n",
    "\n",
    "<a id=\"cite-acharya2018deep\"/><sup><a href=#ref-10>[^]</a></sup>Acharya, U Rajendra and Oh, Shu Lih and Hagiwara, Yuki and Tan, Jen Hong and Adeli, Hojjat. 2018. _Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals_.\n",
    "\n",
    "<a id=\"cite-hussein2018epileptic\"/><sup><a href=#ref-11>[^]</a></sup>Hussein, Ramy and Palangi, Hamid and Ward, Rabab and Wang, Z Jane. 2018. _Epileptic seizure detection: A deep learning approach_.\n",
    "\n",
    "<a id=\"cite-xun2016detecting\"/><sup><a href=#ref-12>[^]</a></sup>Xun, Guangxu and Jia, Xiaowei and Zhang, Aidong. 2016. _Detecting epileptic seizures with electroencephalogram via a context-learning model_.\n",
    "\n",
    "<a id=\"cite-emami2019autoencoding\"/><sup><a href=#ref-14>[^]</a><a href=#ref-22>[^]</a></sup>Emami, Ali and Kunii, Naoto and Matsuo, Takeshi and Shinozaki, Takashi and Kawai, Kensuke and Takahashi, Hirokazu. 2019. _Autoencoding of long-term scalp electroencephalogram to detect epileptic seizure for diagnosis support system_.\n",
    "\n",
    "<a id=\"cite-chollet2018keras\"/><sup><a href=#ref-17>[^]</a></sup>Chollet, Françcois and others. 2018. _Keras: The python deep learning library_.\n",
    "\n",
    "<a id=\"cite-tensorflow\"/><sup><a href=#ref-18>[^]</a></sup>Abadi, Martín and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others. undefined. _Tensorflow: A system for large-scale machine learning_.\n",
    "\n",
    "<a id=\"cite-Fuente:2019\"/><sup><a href=#ref-19>[^]</a></sup>la Fuente, Alfredo De and Aduviri, Robert. 2019. _[Re] Variational Sparse Coding_. [URL](https://zenodo.org/record/3161734/files/Article.pdf)\n",
    "\n",
    "<a id=\"cite-Shoeb\"/><sup><a href=#ref-21>[^]</a></sup>Shoeb, Ali and Guttag, John. 2010. _Application of Machine Learning to Epileptic Seizure Detection_. [URL](http://dl.acm.org/citation.cfm?id=3104322.3104446)\n",
    "\n",
    "<a id=\"cite-Andrzejak\"/><sup><a href=#ref-26>[^]</a></sup>G. Andrzejak, Ralph and Lehnertz, Klaus and Mormann, Florian and Rieke, Christoph and David, Peter and Elger, Christian. 2002. _Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state_.\n",
    "\n",
    "<a id=\"cite-kamath2015analysis\"/><sup><a href=#ref-27>[^]</a></sup>Kamath, Chandrakar. 2015. _Analysis of EEG dynamics in epileptic patients and healthy subjects using Hilbert transform scatter plots_.\n",
    "\n",
    "<a id=\"cite-roy2019deep\"/><sup><a href=#ref-28>[^]</a></sup>Roy, Yannick and Banville, Hubert and Albuquerque, Isabela and Gramfort, Alexandre and Falk, Tiago H and Faubert, Jocelyn. 2019. _Deep learning-based electroencephalography analysis: a systematic review_.\n",
    "\n",
    "<a id=\"cite-how\"/><sup><a href=#ref-31>[^]</a></sup>Lorena, Ana C and Garcia, Luis PF and Lehmann, Jens and Souto, Marcilio CP and Ho, Tin K. 2018. _How Complex is your classification problem? A survey on measuring classification complexity_.\n",
    "\n",
    "<a id=\"cite-benavoli2017time\"/><sup><a href=#ref-32>[^]</a></sup>Benavoli, Alessio and Corani, Giorgio and Demsar, Janez and Zaffalon, Marco. 2017. _Time for a change: a tutorial for comparing multiple classifiers through Bayesian analysis_.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "0RFNpnFIA29s",
    "uw-ParALA29t"
   ],
   "include_colab_link": true,
   "name": "Jupyter_Paper_Re_Deep_Convolution_Neural_Network_and_Autoencoders_Based_Unsupervised_Feature_Learning_of_EEG_Signals.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "re-science",
   "language": "python",
   "name": "re-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "175px",
    "width": "315px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "691.75px",
    "left": "76px",
    "top": "699.333px",
    "width": "433.85px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
